{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f989db39",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "\n",
    "- datasets unfiltered and filtered\n",
    "\n",
    "- third attempt: improved data collection (electrode placement, skin preparation, ...)\n",
    "- best accuracys:\n",
    "    - DATA2 FILTERED Feature combination: MAV, WL, VAR: the average accuracy using cross validation with 10 folds across selected features is 0.8760233918128655\n",
    "    - DATA2 UNFILTERED the average accuracy using cross validation with 10 folds across selected features is 0.8719298245614034\n",
    "        Feature combination: RMS, MAV, WL\n",
    "    - DATA4 keyboard up Feature combination: RMS, MAV, WL: the average accuracy using cross validation with 10 folds across selected features is 0.9452205882352942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75985f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from scipy import stats\n",
    "import time\n",
    "from random import randrange\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221f096",
   "metadata": {},
   "source": [
    "## functions\n",
    "\n",
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006ca8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_file(file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Opens a csv file as pandas dataframe.\n",
    "    Cleans the data by removing all irrelevant data. (direction == 0)\n",
    "    Returns dataframe.\n",
    "    \n",
    "    Args:\n",
    "        file (str): The path to the file to open. \n",
    "        \n",
    "    Returns:\n",
    "        df.dataframe: df including all data for direction 1 and 2\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.read_csv(file)\n",
    "    \n",
    "    # data_up = data.loc[data[\"direction\"]== 1]\n",
    "    # data_down = data.loc[data[\"direction\"]== 2]\n",
    "    #data_clean = data.loc[data[\"direction\"] > 0]\n",
    "    \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263b249",
   "metadata": {},
   "source": [
    "### RMS (root mean square)\n",
    "##### RMS is related to the constant force, and the non-fatiguing contractions of thge muscles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122f4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_per_epoch(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Input is a df filled with emg data, epoch_ids and direction.\n",
    "    Calculates the RootMeanSquare (RMS) per muscle for each epoch.\n",
    "    \n",
    "    Args:\n",
    "        df including all relevant data to calculate\n",
    "        \n",
    "    Returns:\n",
    "        df including RMS per muscle per epoch\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # get n_epoch by finding max value\n",
    "    n_epoch = data['epoch_ix'].max()\n",
    "    \n",
    "    rms_muscle1 = []\n",
    "    rms_muscle2 = []\n",
    "    direction = []\n",
    "\n",
    "    for i in range(1,n_epoch+1):\n",
    "        cases = data.loc[data[\"epoch_ix\"] == i]\n",
    "\n",
    "        # calculate RMS for muscle1 and muscle2\n",
    "        RMS_m1 = np.sqrt(np.sum(np.square(cases.muscle1))/len(cases))\n",
    "        rms_muscle1.append(RMS_m1)\n",
    "\n",
    "        RMS_m2 = np.sqrt(np.sum(np.square(cases.muscle2))/len(cases))\n",
    "        rms_muscle2.append(RMS_m2)\n",
    "\n",
    "        direction.append(cases['direction'].values[0])\n",
    "       \n",
    "    # create data frame with direction and RMS_m1, RMS_m2\n",
    "    rms_data = {'direction': direction, 'rms_m1': rms_muscle1, 'rms_m2': rms_muscle2}\n",
    "    RMS = pd.DataFrame(rms_data)\n",
    "    \n",
    "    return RMS\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37132359",
   "metadata": {},
   "source": [
    "### MAV (mean absolute value)\n",
    "##### MAV is a method of detecting and gauging muscle contraction levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7be1e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mav_per_epoch(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Input is a df filled with emg data, epoch_ids and direction.\n",
    "    Calculates the MeanAbsoluteValue (MAV) per muscle for each epoch.\n",
    "    \n",
    "    Args:\n",
    "        df including all relevant data to calculate\n",
    "        \n",
    "    Returns:\n",
    "        df including mav per muscle per epoch\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # get n_epoch by finding max value\n",
    "    n_epoch = data['epoch_ixs'].max()\n",
    "    \n",
    "    mav_muscle1 = []\n",
    "    mav_muscle2 = []\n",
    "    direction = []\n",
    "\n",
    "    for i in range(1,n_epoch+1):\n",
    "        cases = data.loc[data[\"epoch_ix\"] == i]\n",
    "\n",
    "        # calculate mav for muscle1 and muscle2\n",
    "        MAV_m1 = np.sum(np.absolute(cases.muscle1))/len(cases)      \n",
    "        mav_muscle1.append(MAV_m1)\n",
    "\n",
    "        MAV_m2 = np.sum(np.absolute(cases.muscle2))/len(cases)      \n",
    "        mav_muscle2.append(MAV_m2)\n",
    "\n",
    "        direction.append(cases['direction'].values[0])\n",
    "       \n",
    "    # create data frame with direction and MAV_m1, MAV_m2\n",
    "    mav_data = {'direction': direction, 'mav_m1': mav_muscle1, 'mav_m2': mav_muscle2}\n",
    "    MAV = pd.DataFrame(mav_data)\n",
    "    \n",
    "    return MAV\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2fada",
   "metadata": {},
   "source": [
    "### VAR (variance of EMG)\n",
    "##### expresses the power of the EMG signal as useable feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81e43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_per_epoch(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Input is a df filled with emg data, epoch_ids and direction.\n",
    "    Calculates the variance (VAR) per muscle for each epoch.\n",
    "    \n",
    "    Args:\n",
    "        df including all relevant data to calculate\n",
    "        \n",
    "    Returns:\n",
    "        df including var per muscle per epoch\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # get n_epoch by finding max value\n",
    "    n_epoch = data['epoch_ixs'].max()\n",
    "    \n",
    "    var_muscle1 = []\n",
    "    var_muscle2 = []\n",
    "    direction = []\n",
    "\n",
    "    for i in range(1,n_epoch+1):\n",
    "        cases = data.loc[data[\"epoch_ix\"] == i]\n",
    "        \n",
    "        if len(cases)==1:\n",
    "            print(\"WARNING: epoch\", i, \"is too short; it only contains 1 element.\")\n",
    "            \n",
    "        else:\n",
    "\n",
    "        # calculate VAR for muscle1 and muscle2\n",
    "            VAR_m1 = np.sum(np.square(cases.muscle1))/(len(cases)-1) \n",
    "            var_muscle1.append(VAR_m1)\n",
    "\n",
    "            VAR_m2 = np.sum(np.square(cases.muscle2))/(len(cases)-1)      \n",
    "            var_muscle2.append(VAR_m2)\n",
    "\n",
    "            direction.append(cases['direction'].values[0])\n",
    "       \n",
    "    # create data frame with direction and VAR_m1, VAR_m2\n",
    "    var_data = {'direction': direction, 'var_m1': var_muscle1, 'var_m2': var_muscle2}\n",
    "    VAR = pd.DataFrame(var_data)\n",
    "    \n",
    "    return VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44666a2e",
   "metadata": {},
   "source": [
    "### WL (Waveform Length)\n",
    "##### the WL is intuitively the cummulative length of the waveform over the segment. the resultant values of the WL calculation indicate a measure of the waveform amplitude, frequency, and duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2c221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wl_per_epoch(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Input is a df filled with emg data, epoch_ids and direction.\n",
    "    First finds the shortest epoch n_shortest.\n",
    "    Calculates the waveform length (WL) per muscle for each epoch,\n",
    "    only considering the first n_shortest entries.\n",
    "    \n",
    "    Args:\n",
    "        df including all relevant data to calculate\n",
    "        \n",
    "    Returns:\n",
    "        df including wl per muscle per epoch\n",
    "    \n",
    "    '''\n",
    " \n",
    "    n_epoch = data['epoch_ix'].max()\n",
    "\n",
    "    # find closest epoch_length >=  min_length\n",
    "    n_shortest = 1000\n",
    "    min_length = 10\n",
    "\n",
    "    for i in range(1,n_epoch+1):\n",
    "        epoche_i = data.loc[data[\"epoch_ix\"] == i]\n",
    "\n",
    "        if len(epoche_i) >= min_length and len(epoche_i) <= n_shortest: \n",
    "            n_shortest = len(epoche_i)\n",
    "\n",
    "        elif len(epoche_i) <= min_length:\n",
    "            print('WARNING: epoch', i,'has a length of ',len(epoche_i))\n",
    "\n",
    "\n",
    "    # calculate WL for first n_shortest entries of each epoch\n",
    "    wl_muscle1 = []\n",
    "    wl_muscle2 = []\n",
    "    direction = []\n",
    "\n",
    "    for i in range(1,n_epoch+1):\n",
    "        cases = data.loc[data[\"epoch_ix\"] == i]\n",
    "\n",
    "        # convert pd.series to np.array\n",
    "        arr_m1 = cases.muscle1.to_numpy()\n",
    "        arr_m2 = cases.muscle2.to_numpy()\n",
    "\n",
    "        WL_m1 = 0\n",
    "        WL_m2 = 0\n",
    "\n",
    "        for j in range (1,n_shortest):\n",
    "\n",
    "            WL_m1_curr = np.absolute(arr_m1[j]-arr_m1[(j-1)])\n",
    "            WL_m1 = WL_m1 + WL_m1_curr\n",
    "\n",
    "            WL_m2_curr = np.absolute(arr_m2[j]-arr_m2[(j-1)])\n",
    "            WL_m2 = WL_m2 + WL_m2_curr\n",
    "\n",
    "        wl_muscle1.append(WL_m1)\n",
    "        wl_muscle2.append(WL_m2)\n",
    "\n",
    "        direction.append(cases['direction'].values[0])\n",
    "\n",
    "    wl_data = {'direction': direction, 'wl_m1': wl_muscle1, 'wl_m2': wl_muscle2}\n",
    "    WL = pd.DataFrame(wl_data)\n",
    "    \n",
    "    return WL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75456ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(dataset: pd.DataFrame, RMS = False, MAV = False, VAR = False, WL = False)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates 1-4 features, z_standarisation of the data and combines them to new df.\n",
    "    Select features by setting boolean to True.\n",
    "    \n",
    "    Args:\n",
    "        df: including the labelled data (direction 1 + 2) for both muscles. \n",
    "        feature: optional boolean arg for selected features.\n",
    "        \n",
    "    Returns:\n",
    "        df: combined and z-standarized data.\n",
    "    \"\"\"\n",
    "    \n",
    "    if RMS == MAV == VAR == WL == False:\n",
    "        print('Error. Please select features for combined data.')\n",
    "    \n",
    "    else:\n",
    "        combined_data = None\n",
    "        \n",
    "        if RMS == True:\n",
    "            rms_data = rms_per_epoch(dataset)\n",
    "            combined_data = rms_data\n",
    "                    \n",
    "        if MAV == True:\n",
    "            mav_data = mav_per_epoch(dataset)\n",
    "            \n",
    "            if combined_data is not None:\n",
    "                combined_data = pd.concat([combined_data,mav_data], axis=1)\n",
    "            \n",
    "            else:\n",
    "                combined_data = mav_data\n",
    "            \n",
    "        if VAR == True:\n",
    "            var_data = var_per_epoch(dataset)\n",
    "            \n",
    "            if combined_data is not None:\n",
    "                combined_data = pd.concat([combined_data,var_data], axis=1)\n",
    "            \n",
    "            else:\n",
    "                combined_data = var_data\n",
    "                \n",
    "        if WL == True: \n",
    "            wl_data = wl_per_epoch(dataset)\n",
    "            \n",
    "            if combined_data is not None:\n",
    "                combined_data = pd.concat([combined_data,wl_data], axis=1)\n",
    "                \n",
    "            else:\n",
    "                combined_data = wl_data\n",
    "        \n",
    "        # remove all unneccesary direction columns\n",
    "        combined_data = combined_data.loc[:,~combined_data.columns.duplicated()]\n",
    "        \n",
    "        # z-standarization of all emg data besides direction-labels\n",
    "        ### HERE: z-stamdarization along datapoints per feature\n",
    "        # combined_data.iloc[:,1:] = stats.zscore(combined_data.iloc[:,1:], axis=0)\n",
    "\n",
    "        return combined_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe99f8",
   "metadata": {},
   "source": [
    "**@Nils**: No need to z-score here or with the real-time data, it does not make any difference to the results. However, when plotting the description of the features as a box plot for example, you can zscore to plot them on the same axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f2277b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_pooling(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Uses function combine_data to generate combined data sets.\n",
    "    Pools features and calculates LDA accuracy for different feature pools.\n",
    "    Prints feature combination and score.\n",
    "    \n",
    "    ### option for smarter code: instead of always generating \n",
    "    \n",
    "    Args:\n",
    "        df: including the data set.\n",
    "    \"\"\"\n",
    "    # subsets [0, RMS, RMS, MAV, MAV, WL, WL, VAR, VAR]\n",
    "    \n",
    "    # RMS = True, MAV = True, WL = True, VAR = True\n",
    "    df_all_features = combine_data(data, RMS = True, MAV = True, WL = True, VAR = True)\n",
    "    print('Feature combination: RMS, MAV, WL, VAR')  \n",
    "    LDA_classifier(df_all_features)\n",
    "    \n",
    "    ### instead of df_selected_n possible to use LDA_classifier with specifying subsets\n",
    "    # RMS = FALSE, MAV = True, WL = True, VAR = True \n",
    "    #LDA_classifier(df_all_features, subsets = list(range(3,9)))\n",
    "    # RMS = True, MAV = FALSE, WL = True, VAR = True\n",
    "    #LDA_classifier(df_all_features, subsets = [1,2,5,6,7,8])\n",
    "    # RMS = True, MAV = True, WL = FALSE, VAR = True\n",
    "    #LDA_classifier(df_all_features, subsets = [1,2,3,4,7,8])\n",
    "    # RMS = True, MAV = True, WL = True, VAR = FALSE\n",
    "    #LDA_classifier(df_all_features, subsets = [1,2,3,4,5,6])\n",
    "    # MAV = True, VAR = True\n",
    "    #LDA_classifier(df_all_features, subsets = [3,4,7,8])\n",
    "    \n",
    "    \n",
    "    # RMS = FALSE, MAV = True, WL = True, VAR = True\n",
    "    df_selected_1 = combine_data(data, RMS = False, MAV = True, WL = True, VAR = True)\n",
    "    print('Feature combination: MAV, WL, VAR') \n",
    "    LDA_classifier(df_selected_1)\n",
    "    \n",
    "    # RMS = True, MAV = FALSE, WL = True, VAR = True\n",
    "    df_selected_2 = combine_data(data, RMS = True, MAV = False, WL = True, VAR = True)\n",
    "    print('Feature combination: RMS, WL, VAR') \n",
    "    LDA_classifier(df_selected_2)\n",
    "    \n",
    "    # RMS = True, MAV = True, WL = FALSE, VAR = True\n",
    "    df_selected_3 = combine_data(data, RMS = True, MAV = True, WL = False, VAR = True)\n",
    "    print('Feature combination: RMS, MAV, VAR')\n",
    "    LDA_classifier(df_selected_3)\n",
    "    \n",
    "    # RMS = True, MAV = True, WL = True, VAR = FALSE\n",
    "    df_selected_4 = combine_data(data, RMS = True, MAV = True, WL = True, VAR = False)\n",
    "    print('Feature combination: RMS, MAV, WL')\n",
    "    LDA_classifier(df_selected_4)\n",
    "    \n",
    "    # MAV = True, VAR = True\n",
    "    print('Feature combination: MAV, VAR')\n",
    "    df_selected_5 = combine_data(data, RMS = False, MAV = True, WL = False, VAR = True)\n",
    "    LDA_classifier(df_selected_5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc429d4d",
   "metadata": {},
   "source": [
    "### LDA with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad4a19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_classifier(data: pd.DataFrame, folds = 10, subsets = [], timer = False):\n",
    "    \"\"\"\n",
    "    Trains and tests LDA classifier and calculates the accuracy.\n",
    "    Prints the average accuracy and stadard deviation.\n",
    "    \n",
    "    Args:\n",
    "        df: including the labelled data (direction 1 + 2) for both muscles. \n",
    "        \n",
    "        folds: number of folds; optional argument for cross validation; default value is 10\n",
    "        \n",
    "        subsets (optional): list including the columns of df to do LDA CV on\n",
    "        \n",
    "        timer = True: optional parameter to measure time of CV\n",
    "        \n",
    "    Returns:\n",
    "        None  \n",
    "    \"\"\"\n",
    "    if timer == True:\n",
    "        startTime = time.time()\n",
    "\n",
    "    # clf = LDA(solver='lsqr',shrinkage='auto')\n",
    "    clf = LDA()\n",
    "    \n",
    "    # splits data randomly in n=folds \n",
    "    kfolds = KFold(n_splits=folds, random_state=1, shuffle=True) \n",
    "    \n",
    "    if len(subsets) == 0:\n",
    "        subsets = list(range(1,len(data.columns)))\n",
    "    \n",
    "    cv_results = cross_val_score(clf, data.iloc[:,subsets].values, data.direction, cv=kfolds)\n",
    "    cv_average = cv_results.mean()\n",
    "    st_deviation = cv_results.std()\n",
    "    \n",
    "    #print(cv_results)\n",
    "    \n",
    "    print(\"%0.3f accuracy with a standard deviation of %0.3f\" % (cv_average, st_deviation))\n",
    "\n",
    "    #print(f'the average accuracy using cross validation with {folds} folds across selected features is {cv_average}')\n",
    "    \n",
    "    if timer == True:\n",
    "        cvTime = (time.time() - startTime)\n",
    "        print('Cross Validation time in seconds: ' + str(cvTime))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588f7ec",
   "metadata": {},
   "source": [
    "**@Nils** We can try the shrinkage auto setting later for real-time application and see if it performs better on unseen data than the presumably overfit model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecf4cfc",
   "metadata": {},
   "source": [
    "### Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cbd897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save(data: pd.DataFrame, feature: str, name: str, save: bool = False):\n",
    "    '''\n",
    "    Input is a df filled with data to plot and save.\n",
    "    Plots the data and optionally saves it in current working direction.\n",
    "    \n",
    "    Args:\n",
    "        data: df including all relevant data\n",
    "        feature: str including the feature name\n",
    "        name: str including the name of the data set\n",
    "        save = True to save plot to current working direction.\n",
    "    '''\n",
    "    \n",
    "    x_vals = data.iloc[:,1].name\n",
    "    y_vals = data.iloc[:,2].name\n",
    "    \n",
    "    # plot\n",
    "    g = sns.lmplot(x=x_vals,y=y_vals, data=data, hue='direction', fit_reg=False)\n",
    "    g.set_axis_labels('{} muscle1'.format(feature), '{} muscle2'.format(feature))\n",
    "    plt.title('{} - {}'.format(name, feature))\n",
    "    if save == True:\n",
    "        plt.savefig('./plots/{}_{}.pdf'.format(name, feature),dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # warning when saving as .eps   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426cf202",
   "metadata": {},
   "source": [
    "### DATA EXPLORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a930930",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_from_file(file='C:/Users/willy/Documents/GitHub/2021-fastReach/data/study/eeglab2python/4\\data.csv')\n",
    "\n",
    "#data = read_from_file(file='C:/Users/Nils/Documents/02_Uni/Master Human Factors/\\\n",
    "#00_Masterarbeit/55_github/proxEMG/data/7/1803_test_2_gesture.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2a89ee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'muscle1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2948/2004205346.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeature_pooling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2948/764941647.py\u001b[0m in \u001b[0;36mfeature_pooling\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# RMS = True, MAV = True, WL = True, VAR = True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdf_all_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVAR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature combination: RMS, MAV, WL, VAR'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mLDA_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_all_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2948/2854234285.py\u001b[0m in \u001b[0;36mcombine_data\u001b[1;34m(dataset, RMS, MAV, VAR, WL)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mRMS\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mrms_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrms_per_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mcombined_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrms_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2948/3034063203.py\u001b[0m in \u001b[0;36mrms_per_epoch\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# calculate RMS for muscle1 and muscle2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mRMS_m1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcases\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmuscle1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcases\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mrms_muscle1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRMS_m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'muscle1'"
     ]
    }
   ],
   "source": [
    "feature_pooling(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "data_rms = rms_per_epoch(data)\n",
    "data_mav = mav_per_epoch(data)\n",
    "data_var = var_per_epoch(data)\n",
    "data_wl = wl_per_epoch(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data points m1 + m2 per feature\n",
    "plot_and_save(data_rms, feature='RMS', name='1803_test_rotation', save=False)\n",
    "plot_and_save(data_mav, feature='MAV', name='1803_test_rotation', save=False)\n",
    "plot_and_save(data_var, feature='VAR', name='1803_test_rotation', save=False)\n",
    "plot_and_save(data_wl, feature='WL', name='1803_test_rotation', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1798ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting dim reduction \n",
    "all_data = combine_data(data, RMS = True, MAV = True, WL = False, VAR = True)\n",
    "\n",
    "# generate \"fake\" third class to allow n_components=2\n",
    "all_data.loc[0]=[0,0,0,0,0,0,0]\n",
    "\n",
    "clf = LDA(n_components=2)\n",
    "\n",
    "transf_lda = clf.fit_transform(all_data.iloc[:,list(range(1,7))].values, all_data.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a74cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,marker,color in zip(range(1,3),('o','^'),('red','blue')):\n",
    "    plt.scatter(x=transf_lda[:,0][all_data.direction == label],\n",
    "           y=transf_lda[:,1][all_data.direction == label], marker=marker,\n",
    "           color=color, alpha=0.7, label='class {}'.format(label))\n",
    "\n",
    "plt.xlabel('linear discriminant 1')\n",
    "plt.ylabel('linear discriminant 2')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('dimensionality reduction for 1803 rotation data set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc40db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### variance explained by each coefficient \n",
    "# NOTE: vertauscht im Vgl. zu plot?\n",
    "clf.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f2400",
   "metadata": {},
   "source": [
    "## code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ae270",
   "metadata": {},
   "source": [
    "#### direction 1 and odd epoch_ixs --> clockwise; direction 2 and even epoch_ixs --> anticlockwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae57160",
   "metadata": {},
   "source": [
    "#### data_2: muscles 8-28 and 8-50; reference: wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4313c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfiltered\n",
    "data_2 = read_from_file(file='C:/Users/Nils/Documents/02_Uni/Master Human Factors/\\\n",
    "00_Masterarbeit/55_github/proxEMG/data/4/data_2.csv')\n",
    "\n",
    "#data_2 = read_from_file(file='/Users/lukasgehrke/Documents/publications/proxEMG/data/4/data_2.csv')\n",
    "\n",
    "# feature pooling\n",
    "feature_pooling(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068753ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting dim reduction \n",
    "all_data = combine_data(data_2, RMS = True, MAV = True, WL = True, VAR = True)\n",
    "\n",
    "# generate \"fake\" third class to allow n_components=2\n",
    "all_data.loc[0]=[0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "clf = LDA(n_components=2)\n",
    "\n",
    "transf_lda = clf.fit_transform(all_data.iloc[:,list(range(1,9))].values, all_data.direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23083268",
   "metadata": {},
   "source": [
    "**@Nils**: in the below plot please label the axes as linear discriminant #1 and #2. Now I see why you add the 0, it is fine, doesnt change anything about the data. \n",
    "I assume the axes show **centered** scores right? So you can also draw a vertical line at 0 as the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,marker,color in zip(range(1,3),('o','^'),('red','blue')):\n",
    "    plt.scatter(x=transf_lda[:,0][all_data.direction == label],\n",
    "           y=transf_lda[:,1][all_data.direction == label], marker=marker,\n",
    "           color=color, alpha=0.7, label='class {}'.format(label))\n",
    "\n",
    "plt.xlabel('linear discriminant 1')\n",
    "plt.ylabel('linear discriminant 2')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('dimensionality reduction for data set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ca33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting dim reduction \n",
    "all_data_1d = combine_data(data_2, RMS = True, MAV = True, WL = True, VAR = True)\n",
    "\n",
    "# generate \"fake\" third class to allow n_components=2\n",
    "#all_data.loc[0]=[0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "clf_1d = LDA(n_components=1)\n",
    "\n",
    "transf_lda_1d = clf_1d.fit_transform(all_data_1d.iloc[:,list(range(1,9))].values, all_data_1d.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf9cd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake y for scatter plot\n",
    "y = np.ones(np.shape(transf_lda[:,0]))\n",
    "\n",
    "for label,marker,color in zip(range(1,3),('o','^'),('red','blue')):\n",
    "    plt.scatter(x=transf_lda[:,0][all_data.direction == label],\n",
    "           y=y[all_data.direction == label], marker=marker,\n",
    "           color=color, alpha=0.7, label='class {}'.format(label))\n",
    "\n",
    "#plt.xlabel('vector 1')\n",
    "#plt.ylabel('vector 2')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('dimensionality reduction for data set')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d188ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered\n",
    "data_2_filtered = read_from_file(file='/Users/lukasgehrke/Documents/publications/proxEMG/data/4/data_2_filtered.csv')\n",
    "\n",
    "# feature pooling\n",
    "feature_pooling(data_2_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e83066",
   "metadata": {},
   "source": [
    "#### TEST of classifier to classify single datapoint\n",
    "\n",
    "1. fit classifier with data\n",
    "2. pick example to classify\n",
    "3. prediction probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f169cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### classifier for MAV, WL, VAR\n",
    "\n",
    "# generate training data \n",
    "data = combine_data(data, RMS = True, MAV = True, WL = False, VAR = True)\n",
    "\n",
    "# fit classifier according to training data\n",
    "clf = LDA()\n",
    "subsets = list(range(1,7))\n",
    "clf.fit(data.iloc[:,subsets].values, data.direction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de546121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick random epoch as example\n",
    "example_idx = randrange(1,len(data.direction))\n",
    "\n",
    "example = data.iloc[example_idx,subsets]\n",
    "\n",
    "# pd.series to np.array\n",
    "np_example = example.to_numpy()\n",
    "reshaped = np_example.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f50886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for random epoch\n",
    "\n",
    "prediction = clf.predict(reshaped)[0] #predicted class\n",
    "\n",
    "probs = clf.predict_proba(reshaped) #probability prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7e4854",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.8\n",
    "if probs[0][prediction-1] > threshold: #-1 da class 1,2 und index 0,1\n",
    "    print(\"above threshold\", probs[0][prediction-1])\n",
    "else:\n",
    "    print(\"below threshold\", probs[0][prediction-1])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed0bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show picked example\n",
    "data.iloc[example_idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455a988",
   "metadata": {},
   "source": [
    "#### per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "data_2_rms = rms_per_epoch(data_2)\n",
    "data_2_mav = mav_per_epoch(data_2)\n",
    "data_2_var = var_per_epoch(data_2)\n",
    "data_2_wl = wl_per_epoch(data_2)\n",
    "\n",
    "# filtered\n",
    "data_2_filtered_rms = rms_per_epoch(data_2_filtered)\n",
    "data_2_filtered_mav = mav_per_epoch(data_2_filtered)\n",
    "data_2_filtered_var = var_per_epoch(data_2_filtered)\n",
    "data_2_filtered_wl = wl_per_epoch(data_2_filtered)\n",
    "\n",
    "# plot data points m1 + m2 per feature\n",
    "plot_and_save(data_2_rms, feature='RMS', name='data_2', save=True)\n",
    "plot_and_save(data_2_mav, feature='MAV', name='data_2', save=True)\n",
    "plot_and_save(data_2_var, feature='VAR', name='data_2', save=True)\n",
    "plot_and_save(data_2_wl, feature='WL', name='data_2', save=True)\n",
    "\n",
    "# filtered\n",
    "plot_and_save(data_2_filtered_rms, feature='RMS', name='data_2_filtered', save=True)\n",
    "plot_and_save(data_2_filtered_mav, feature='MAV', name='data_2_filtered', save=True)\n",
    "plot_and_save(data_2_filtered_var, feature='VAR', name='data_2_filtered', save=True)\n",
    "plot_and_save(data_2_filtered_wl, feature='WL', name='data_2_filtered', save=True)\n",
    "\n",
    "# calculate LDA accuracy per feature\n",
    "LDA_classifier(data_2_rms)\n",
    "LDA_classifier(data_2_mav)\n",
    "LDA_classifier(data_2_var)\n",
    "LDA_classifier(data_2_wl)\n",
    "\n",
    "# filtered\n",
    "LDA_classifier(data_2_filtered_rms)\n",
    "LDA_classifier(data_2_filtered_mav)\n",
    "LDA_classifier(data_2_filtered_var)\n",
    "LDA_classifier(data_2_filtered_wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3e8292",
   "metadata": {},
   "source": [
    "#### data_3: muscles 8-29 and 8-38; reference: wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177437e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfiltered\n",
    "# load data\n",
    "data_3 = read_from_file(file='C:/Users/Nils/Documents/02_Uni/Master Human Factors/\\\n",
    "00_Masterarbeit/55_github/proxEMG/data/4/data_3.csv')\n",
    "\n",
    "# feature pooling\n",
    "feature_pooling(data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered\n",
    "data_3_filtered = read_from_file(file='C:/Users/Nils/Documents/02_Uni/Master Human Factors/\\\n",
    "00_Masterarbeit/55_github/proxEMG/data/4/data_3_filtered.csv')\n",
    "\n",
    "# feature pooling\n",
    "feature_pooling(data_3_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "data_3_rms = rms_per_epoch(data_3)\n",
    "data_3_mav = mav_per_epoch(data_3)\n",
    "data_3_var = var_per_epoch(data_3)\n",
    "data_3_wl = wl_per_epoch(data_3)\n",
    "\n",
    "# filtered\n",
    "data_3_filtered_rms = rms_per_epoch(data_3_filtered)\n",
    "data_3_filtered_mav = mav_per_epoch(data_3_filtered)\n",
    "data_3_filtered_var = var_per_epoch(data_3_filtered)\n",
    "data_3_filtered_wl = wl_per_epoch(data_3_filtered)\n",
    "\n",
    "# plot data points m1 + m2 per feature\n",
    "plot_and_save(data_3_rms, feature='RMS', name='data_3', save=True)\n",
    "plot_and_save(data_3_mav, feature='MAV', name='data_3', save=True)\n",
    "plot_and_save(data_3_var, feature='VAR', name='data_3', save=True)\n",
    "plot_and_save(data_3_wl, feature='WL', name='data_3', save=True)\n",
    "\n",
    "# filtered\n",
    "plot_and_save(data_3_filtered_rms, feature='RMS', name='data_3_filtered', save=True)\n",
    "plot_and_save(data_3_filtered_mav, feature='MAV', name='data_3_filtered', save=True)\n",
    "plot_and_save(data_3_filtered_var, feature='VAR', name='data_3_filtered', save=True)\n",
    "plot_and_save(data_3_filtered_wl, feature='WL', name='data_3_filtered', save=True)\n",
    "\n",
    "# calculate LDA accuracy per feature\n",
    "LDA_classifier(data_3_rms)\n",
    "LDA_classifier(data_3_mav)\n",
    "LDA_classifier(data_3_var)\n",
    "LDA_classifier(data_3_wl)\n",
    "\n",
    "# filtered\n",
    "LDA_classifier(data_3_filtered_rms)\n",
    "LDA_classifier(data_3_filtered_mav)\n",
    "LDA_classifier(data_3_filtered_var)\n",
    "LDA_classifier(data_3_filtered_wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c80a569",
   "metadata": {},
   "source": [
    "#### data_4: muscle selection like in data_3, but with keyboard up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfiltered\n",
    "# load data\n",
    "data_4 = read_from_file(file='C:/Users/Nils/Documents/02_Uni/Master Human Factors/\\\n",
    "00_Masterarbeit/55_github/proxEMG/data/4/data_4.csv')\n",
    "\n",
    "# feature pooling\n",
    "feature_pooling(data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb556902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered\n",
    "data_4_filtered = read_from_file(file='C:/Users/Nils/Documents/02_Uni/Master Human Factors/\\\n",
    "00_Masterarbeit/55_github/proxEMG/data/4/data_4_filtered.csv')\n",
    "\n",
    "# feature pooling\n",
    "feature_pooling(data_4_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e326239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting dim reduction \n",
    "all_data_keyboard_up = combine_data(data_4_filtered, RMS = True, MAV = True, WL = True, VAR = True)\n",
    "\n",
    "# generate \"fake\" third class to allow n_components=2\n",
    "all_data_keyboard_up.loc[0]=[0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "clf_keyboard_up = LDA(n_components=2)\n",
    "\n",
    "transf_lda_keyboard_up = clf_keyboard_up.fit_transform(all_data_keyboard_up.iloc[:,list(range(1,9))].values, all_data_keyboard_up.direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label,marker,color in zip(range(1,3),('o','^'),('red','blue')):\n",
    "    plt.scatter(x=transf_lda_keyboard_up[:,0][all_data_keyboard_up.direction == label],\n",
    "           y=transf_lda_keyboard_up[:,1][all_data_keyboard_up.direction == label], marker=marker,\n",
    "           color=color, alpha=0.7, label='class {}'.format(label))\n",
    "\n",
    "plt.xlabel('vector 1')\n",
    "plt.ylabel('vector 2')\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('dimensionality reduction for data set \"keyboard up\"')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b806560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature extraction\n",
    "data_4_rms = rms_per_epoch(data_4)\n",
    "data_4_mav = mav_per_epoch(data_4)\n",
    "data_4_var = var_per_epoch(data_4)\n",
    "data_4_wl = wl_per_epoch(data_4)\n",
    "\n",
    "# filtered\n",
    "data_4_filtered_rms = rms_per_epoch(data_4_filtered)\n",
    "data_4_filtered_mav = mav_per_epoch(data_4_filtered)\n",
    "data_4_filtered_var = var_per_epoch(data_4_filtered)\n",
    "data_4_filtered_wl = wl_per_epoch(data_4_filtered)\n",
    "\n",
    "# plot data points m1 + m2 per feature\n",
    "plot_and_save(data_4_rms, feature='RMS', name='data_4', save=True)\n",
    "plot_and_save(data_4_mav, feature='MAV', name='data_4', save=True)\n",
    "plot_and_save(data_4_var, feature='VAR', name='data_4', save=True)\n",
    "plot_and_save(data_4_wl, feature='WL', name='data_4', save=True)\n",
    "\n",
    "# filtered\n",
    "plot_and_save(data_4_filtered_rms, feature='RMS', name='data_4_filtered', save=True)\n",
    "plot_and_save(data_4_filtered_mav, feature='MAV', name='data_4_filtered', save=True)\n",
    "plot_and_save(data_4_filtered_var, feature='VAR', name='data_4_filtered', save=True)\n",
    "plot_and_save(data_4_filtered_wl, feature='WL', name='data_4_filtered', save=True)\n",
    "\n",
    "# calculate LDA accuracy per feature\n",
    "LDA_classifier(data_4_rms)\n",
    "LDA_classifier(data_4_mav)\n",
    "LDA_classifier(data_4_var)\n",
    "LDA_classifier(data_4_wl)\n",
    "\n",
    "# filtered\n",
    "LDA_classifier(data_4_filtered_rms)\n",
    "LDA_classifier(data_4_filtered_mav)\n",
    "LDA_classifier(data_4_filtered_var)\n",
    "LDA_classifier(data_4_filtered_wl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f30f5",
   "metadata": {},
   "source": [
    "## gesture recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3945ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_gesture = pd.read_csv('C:/Users/Nils/Documents/02_Uni/Master Human Factors/\\\n",
    "00_Masterarbeit/55_github/proxEMG/data/5/offset_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "data_clean = data_gesture.loc[data_gesture[\"gesture_on\"] > 0]\n",
    "\n",
    "# set of removed data points\n",
    "data_removed = data_gesture.loc[data_gesture[\"gesture_on\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a4ce6",
   "metadata": {},
   "source": [
    "- exact feature calculation needs to be tested\n",
    "- MAV as \"method of detecting and gauging muscle contraction levels\"\n",
    "- VAR \"expresses the power of the EMG signal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.loc[data_clean[\"epoch_ixs\"] == 5]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature calculation per epoch\n",
    "\n",
    "# get n_epoch by finding max value\n",
    "idx_max = data_clean['epoch_ixs'].max()\n",
    "mav_m1 = []\n",
    "mav_m2 = []\n",
    "var_m1 = []\n",
    "var_m2 = []\n",
    "\n",
    "for i in range(1,idx_max+1):\n",
    "    cases = data_clean.loc[data_clean[\"epoch_ixs\"] == i]\n",
    "    \n",
    "    #MAV\n",
    "    MAV_m1 = np.sum(np.absolute(cases.muscle1))/len(cases)      \n",
    "    mav_m1.append(MAV_m1)\n",
    "\n",
    "    MAV_m2 = np.sum(np.absolute(cases.muscle2))/len(cases)      \n",
    "    mav_m2.append(MAV_m2)\n",
    "    \n",
    "    if len(cases)==1:\n",
    "        print(\"WARNING: epoch\", i, \"is too short; it only contains 1 element.\")\n",
    "            \n",
    "    else:\n",
    "    \n",
    "        #VAR\n",
    "        VAR_m1 = np.sum(np.square(cases.muscle1))/(len(cases)-1) \n",
    "        var_m1.append(VAR_m1)\n",
    "\n",
    "        VAR_m2 = np.sum(np.square(cases.muscle2))/(len(cases)-1)      \n",
    "        var_m2.append(VAR_m2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa046df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature calculation for removed data\n",
    "\n",
    "# opt. 1) over all data\n",
    "MAV_m1_rem = np.sum(np.absolute(data_removed.muscle1))/len(data_removed) \n",
    "MAV_m2_rem = np.sum(np.absolute(data_removed.muscle2))/len(data_removed) \n",
    "\n",
    "# mean vector (no \"really mean\")\n",
    "MAV_mean_removed = (MAV_m1_rem, MAV_m2_rem)\n",
    "\n",
    "# opt. 2) over seperated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f32eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature calculation for removed data\n",
    "\n",
    "# opt. 1) over all data\n",
    "VAR_m1_rem = np.sum(np.square(data_removed.muscle1))/(len(data_removed)-1)\n",
    "VAR_m2_rem = np.sum(np.square(data_removed.muscle2))/(len(data_removed)-1)\n",
    "\n",
    "# mean vector (no \"really mean\")\n",
    "VAR_mean_removed = (VAR_m1_rem, VAR_m2_rem)\n",
    "\n",
    "# opt. 2) over seperated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fc3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean vector\n",
    "MAV_mean = (statistics.mean(mav_m1), statistics.mean(mav_m2))\n",
    "\n",
    "# vgl. mean vector of removed data\n",
    "MAV_mean_removed = (MAV_m1_rem, MAV_m2_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean vector\n",
    "VAR_mean = (statistics.mean(var_m1), statistics.mean(var_m2))\n",
    "\n",
    "# vgl. mean vector of removed data\n",
    "VAR_mean_removed = (VAR_m1_rem, VAR_m2_rem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24c987",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_mean_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c05aa4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
