@ARTICLE{Fleury2020-lb,
  title    = "A Survey on the Use of Haptic Feedback for {Brain-Computer}
              Interfaces and Neurofeedback",
  author   = "Fleury, Mathis and Lioi, Giulia and Barillot, Christian and
              L{\'e}cuyer, Anatole",
  abstract = "Neurofeedback (NF) and brain-computer interface (BCI)
              applications rely on the registration and real-time feedback of
              individual patterns of brain activity with the aim of achieving
              self-regulation of specific neural substrates or control of
              external devices. These approaches have historically employed
              visual stimuli. However, in some cases vision is unsuitable or
              inadequately engaging. Other sensory modalities, such as auditory
              or haptic feedback have been explored, and multisensory
              stimulation is expected to improve the quality of the interaction
              loop. Moreover, for motor imagery tasks, closing the sensorimotor
              loop through haptic feedback may be relevant for motor
              rehabilitation applications, as it can promote plasticity
              mechanisms. This survey reviews the various haptic technologies
              and describes their application to BCIs and NF. We identify major
              trends in the use of haptic interfaces for BCI and NF systems and
              discuss crucial aspects that could motivate further studies.",
  journal  = "Front. Neurosci.",
  volume   =  14,
  pages    = "528",
  month    =  jun,
  year     =  2020,
  keywords = "BCI; BMI; EEG; fMRI; haptic feedback; multisensory;
              neurofeedback; touch;fastReach",
  language = "en"
}

@INPROCEEDINGS{Jeong2017-ki,
  title     = "Single-trial analysis of readiness potentials for lower limb
               exoskeleton control",
  booktitle = "2017 5th International Winter Conference on {Brain-Computer}
               Interface ({BCI})",
  author    = "Jeong, Ji-Hoon and Lee, Min-Ho and Kwak, No-Sang and Lee,
               Seong-Whan",
  abstract  = "Bran-machine interface (BMI) can be used for controlling of
               external devices such as the exoskeleton, robot arm, etc. For
               efficient communication between a user and machine, fast and
               accurate detection of user intention is important elements in
               the BMI application. For this reason, readiness potential (RP)
               is a useful feature that is possible to detect movement
               intention before the movement onset. To our knowledge, however,
               the analysis of single-trial RP component has not been
               sufficiently investigated in the real-world application (e.g.
               powered exoskeleton or robot arm). In our study, we first
               validate a single-trial RP performance in the lower limb
               exoskeleton environment where the user allows for voluntary
               walking. The experiments are executed in the two different
               walking conditions which are normal and exoskeleton walking. The
               Laplacian and common average reference (CAR) filters are applied
               to reduce spatial noise and regularized linear discriminant
               analysis (RLDA) is used as a classifier. Our results show the
               averaged classification accuracy of 80.7\% for 5 subjects. This
               study demonstrates a feasibility of RP-based BMI system for
               controlling of a lower limb exoskeleton.",
  pages     = "50--52",
  month     =  jan,
  year      =  2017,
  keywords  = "Brain-machine interface; Lower limb exoskeleton; Readiness
               potential; Single-Trial analysis; Exoskeletons; Legged
               locomotion; Brain modeling; Silicon;fastReach"
}

@ARTICLE{Eden2021-kp,
  title         = "Human movement augmentation and how to make it a reality",
  author        = "Eden, Jonathan and Br{\"a}cklein, Mario and Pereda, Jaime
                   Ib{\'a}{\~n}ez and Barsakcioglu, Deren Yusuf and Di Pino,
                   Giovanni and Farina, Dario and Burdet, Etienne and Mehring,
                   Carsten",
  abstract      = "Augmenting the body with artificial limbs controlled
                   concurrently to the natural limbs has long appeared in
                   science fiction, but recent technological and
                   neuroscientific advances have begun to make this vision
                   possible. By allowing individuals to achieve otherwise
                   impossible actions, this movement augmentation could
                   revolutionize medical and industrial applications and
                   profoundly change the way humans interact with their
                   environment. Here, we construct a movement augmentation
                   taxonomy through what is augmented and how it is achieved.
                   With this framework, we analyze augmentation that extends
                   the number of degrees-of-freedom, discuss critical features
                   of effective augmentation such as physiological control
                   signals, sensory feedback and learning, and propose a vision
                   for the field.",
  number        = "Fetopen 899626",
  pages         = "1--17",
  month         =  jun,
  year          =  2021,
  keywords      = "fastReach;Springer-Affordances\_in\_HCI",
  archivePrefix = "arXiv",
  primaryClass  = "cs.RO",
  eprint        = "2106.08129"
}

@ARTICLE{Schurger2021-vp,
  title     = "What Is the Readiness Potential?",
  author    = "Schurger, Aaron and Hu, Pengbo 'ben' and Pak, Joanna and
               Roskies, Adina L",
  abstract  = "The readiness potential (RP), a slow buildup of electrical
               potential recorded at the scalp using electroencephalography,
               has been associated with neural activity involved in movement
               preparation. It became famous thanks to Benjamin Libet (Brain
               1983;106:623-642), who used the time difference between the RP
               and self-reported time of conscious intention to move to argue
               that we lack free will. The RP's informativeness about
               self-generated action and derivatively about free will has
               prompted continued research on this neural phenomenon. Here, we
               argue that recent advances in our understanding of the RP,
               including computational modeling of the phenomenon, call for a
               reassessment of its relevance for understanding volition and the
               philosophical problem of free will.",
  journal   = "Trends Cogn. Sci.",
  publisher = "The Authors",
  volume    =  25,
  number    =  7,
  pages     = "558--570",
  month     =  jul,
  year      =  2021,
  keywords  = "computational model; consciousness; decision; free will;
               intention; volition;fastReach;RP for HCI",
  language  = "en"
}

@INPROCEEDINGS{Goto2020-mw,
  title     = "Accelerating Skill Acquisition of {Two-Handed} Drumming using
               Pneumatic Artificial Muscles",
  booktitle = "Proceedings of the Augmented Humans International Conference",
  author    = "Goto, Takashi and Das, Swagata and Wolf, Katrin and Lopes, Pedro
               and Kurita, Yuichi and Kunze, Kai",
  abstract  = "While computers excel at augmenting user's cognitive abilities,
               only recently we started utilizing their full potential to
               enhance our physical abilities. More and more wearable
               force-feedback devices have been developed based on
               exoskeletons, electrical muscle stimulation (EMS) or pneumatic
               actuators. The latter, pneumatic-based artificial muscles, are
               of particular interest since they strike an interesting balance:
               lighter than exoskeletons and more precise than EMS. However,
               the promise of using artificial muscles to actually support
               skill acquisition and training users is still lacking empirical
               validation.In this paper, we unveil how pneumatic artificial
               muscles impact skill acquisition, using two-handed drumming as
               an example use case. To understand this, we conducted a user
               study comparing participants' drumming performance after
               training with the audio or with our artificial-muscle setup. Our
               haptic system is comprised of four pneumatic muscles and is
               capable of actuating the user's forearm to drum accurately up to
               80 bpm. We show that pneumatic muscles improve participants'
               correct recall of drumming patterns significantly when compared
               to auditory training.",
  publisher = "Association for Computing Machinery",
  number    = "Article 12",
  pages     = "1--9",
  series    = "AHs '20",
  month     =  mar,
  year      =  2020,
  address   = "New York, NY, USA",
  keywords  = "Force-feedback; motor learning; pneumatic artificial muscles
               (PAMs);BCInt;fastReach;workshop\_reading\_material;pianI/O",
  location  = "Kaiserslautern, Germany"
}

@ARTICLE{Verbaarschot2016-mv,
  title     = "Detecting traces of consciousness in the process of intending to
               act",
  author    = "Verbaarschot, Ceci and Haselager, Pim and Farquhar, Jason",
  abstract  = "An intention to act has different onsets when it is measured in
               different ways. When participants provide a self-initiated
               report on the onset of their awareness of intending to act, the
               report occurs around 150 ms prior to action. However, when the
               same participants are repeatedly asked about their awareness of
               intending at different points in time, the onset of intending is
               found up to 2 s prior to action. This 'probed' awareness has its
               onset around the same time as the brain starts preparing the
               act, as measured using EEG. First of all, this undermines
               straightforward interpretations about the temporal relation
               between unconscious brain states and conscious intentions and
               actions. Secondly, we suggest that these results present a
               problem for the view that intentions are mental states occurring
               at a single point in time. Instead, we suggest the results to
               support the interpretation of an intention to act as a
               multistage process developing over time. This process of
               intending seems to develop during the process of acting, leaving
               reportable traces in consciousness at certain points along the
               road.",
  journal   = "Exp. Brain Res.",
  publisher = "Springer Berlin Heidelberg",
  volume    =  234,
  number    =  7,
  pages     = "1945--1956",
  month     =  jul,
  year      =  2016,
  keywords  = "Action; EEG; ERD; Intention; LRP; RP;BCInt;fastReach",
  language  = "en"
}

@ARTICLE{Luppi2008-cr,
  title     = "Comentario a prop{\'o}sito de la presentaci{\'o}n de la Dra.
               Elza Berqu{\'o}. Reflexiones te{\'o}rico metodol{\'o}gicas sobre
               la elaboraci{\'o}n de cuestionarios de encuesta: una experiencia
               de integraci{\'o}n de enfoques",
  author    = "Luppi, Irene",
  abstract  = "Se presenta una reflexi{\'o}n te{\'o}rico metodol{\'o}gica sobre
               la elaboraci{\'o}n de cuestionarios de encuesta recuperando dos
               cuestiones claves se{\~n}aladas por la Dra. Berqu{\'o}, en su
               testimonio sobre las iniciativas desarrolladas en el campo de la
               salud reproductiva con el objetivo de producir datos que se
               puedan utilizar para formular pol{\'\i}ticas e implementar
               intervenciones en los distintos contextos: la complejidad y la
               flexibilidad. En particular, cuando se abordan cuestiones de
               mayor dificultad para su objetivaci{\'o}n, tales como los
               pareceres, las valoraciones de los sujetos en relaci{\'o}n con
               sus pr{\'a}cticas y las experiencias de padecimiento y cuidado.
               Se enfatiza la necesidad de un riguroso examen de las
               categor{\'\i}as anal{\'\i}ticas susceptibles de ser tratadas
               emp{\'\i}ricamente y de la funcionalidad de los conceptos para
               la producci{\'o}n de indicadores de contenidos sistematizables
               para la comparaci{\'o}n estad{\'\i}stica. Se presenta una
               experiencia de aplicaci{\'o}n de un cuestionario, como instancia
               de integraci{\'o}n metodol{\'o}gica en una investigaci{\'o}n por
               encuesta, destinada a lograr una aproximaci{\'o}n directa al
               universo de representaciones y valoraciones de la mujer, no
               mediada por los c{\'o}digos y la l{\'o}gica de quien las indaga.
               Para su confecci{\'o}n se recuperaron los hallazgos de una
               investigaci{\'o}n antropol{\'o}gica preliminar y se arm{\'o} un
               dispositivo de preguntas con expresiones textuales de las
               entrevistadas, a la manera de un esquema de apoyo del discurso
               de la mujer. La propuesta presentada, de relativa simplicidad,
               puede contribuir a superar dificultades vinculadas con la
               viabilidad de captaci{\'o}n de determinadas tem{\'a}ticas
               seg{\'u}n los contextos socioculturales, a nivel internacional.",
  journal   = "Rev. Bras. Epidemiol.",
  publisher = "Associa{\c c}{\~a}o Brasileira de Sa{\'u}de Coletiva",
  volume    =  11,
  number    = "SUPPL. 1",
  pages     = "90--97",
  month     =  may,
  year      =  2008,
  keywords  = "Cuestionarios de encuesta; Integraci{\'o}n metodol{\'o}gica;
               Operacionalizaci{\'o}n de conceptos;fastReach",
  language  = "es"
}

@ARTICLE{Balasubramanian2018-gu,
  title    = "Is {EMG} a Viable Alternative to {BCI} for Detecting Movement
              Intention in Severe Stroke?",
  author   = "Balasubramanian, Sivakumar and Garcia-Cossio, Eliana and
              Birbaumer, Niels and Burdet, Etienne and Ramos-Murguialday, Ander",
  abstract = "OBJECTIVE: In light of the shortcomings of current restorative
              brain-computer interfaces (BCI), this study investigated the
              possibility of using EMG to detect hand/wrist extension movement
              intention to trigger robot-assisted training in individuals
              without residual movements. METHODS: We compared movement
              intention detection using an EMG detector with a sensorimotor
              rhythm based EEG-BCI using only ipsilesional activity. This was
              carried out on data of 30 severely affected chronic stroke
              patients from a randomized control trial using an EEG-BCI for
              robot-assisted training. RESULTS: The results indicate the
              feasibility of using EMG to detect movement intention in this
              severely handicapped population; probability of detecting EMG
              when patients attempted to move was higher (p 0.001) than at
              rest. Interestingly, 22 out of 30 (or 73\%) patients had
              sufficiently strong EMG in their finger/wrist extensors.
              Furthermore, in patients with detectable EMG, there was poor
              agreement between the EEG and EMG intent detectors, which
              indicates that these modalities may detect different processes.
              CONCLUSION: A substantial segment of severely affected stroke
              patients may benefit from EMG-based assisted therapy. When
              compared to EEG, a surface EMG interface requires less
              preparation time, which is easier to don/doff, and is more
              compact in size. SIGNIFICANCE: This study shows that a large
              proportion of severely affected stroke patients have residual
              EMG, which yields a direct and practical way to trigger
              robot-assisted training.",
  journal  = "IEEE Trans. Biomed. Eng.",
  volume   =  65,
  number   =  12,
  pages    = "2790--2797",
  month    =  dec,
  year     =  2018,
  keywords = "BCI; EMG; Stroke; movement intention;
              neurorehabilitation;fastReach;RP for HCI",
  language = "en"
}

@ARTICLE{Lew2012-wu,
  title    = "Detection of self-paced reaching movement intention from {EEG}
              signals",
  author   = "Lew, Eileen and Chavarriaga, Ricardo and Silvoni, Stefano and
              Mill{\'a}n, Jos{\'e} Del R",
  abstract = "Future neuroprosthetic devices, in particular upper limb, will
              require decoding and executing not only the user's intended
              movement type, but also when the user intends to execute the
              movement. This work investigates the potential use of brain
              signals recorded non-invasively for detecting the time before a
              self-paced reaching movement is initiated which could contribute
              to the design of practical upper limb neuroprosthetics. In
              particular, we show the detection of self-paced reaching movement
              intention in single trials using the readiness potential, an
              electroencephalography (EEG) slow cortical potential (SCP)
              computed in a narrow frequency range (0.1-1 Hz). Our experiments
              with 12 human volunteers, two of them stroke subjects, yield high
              detection rates prior to the movement onset and low detection
              rates during the non-movement intention period. With the proposed
              approach, movement intention was detected around 500 ms before
              actual onset, which clearly matches previous literature on
              readiness potentials. Interestingly, the result obtained with one
              of the stroke subjects is coherent with those achieved in healthy
              subjects, with single-trial performance of up to 92\% for the
              paretic arm. These results suggest that, apart from contributing
              to our understanding of voluntary motor control for designing
              more advanced neuroprostheses, our work could also have a direct
              impact on advancing robot-assisted neurorehabilitation.",
  journal  = "Front. Neuroeng.",
  volume   =  5,
  number   = "JULY",
  pages    = "13",
  month    =  jul,
  year     =  2012,
  keywords = "BCI; EEG; Rehabilitation; Self-paced protocol; Stroke; Voluntary
              movements;BCInt;fastReach;RP for HCI;affordance I/O",
  language = "en"
}

@ARTICLE{Gannouni2020-ru,
  title    = "{EEG-Based} {BCI} System to Detect Fingers Movements",
  author   = "Gannouni, Sofien and Belwafi, Kais and Aboalsamh, Hatim and
              AlSamhan, Ziyad and Alebdi, Basel and Almassad, Yousef and
              Alobaedallah, Homoud",
  abstract = "The advancement of assistive technologies toward the restoration
              of the mobility of paralyzed and/or amputated limbs will go a
              long way. Herein, we propose a system that adopts the
              brain-computer interface technology to control prosthetic fingers
              with the use of brain signals. To predict the movements of each
              finger, complex electroencephalogram (EEG) signal processing
              algorithms should be applied to remove the outliers, extract
              features, and be able to handle separately the five human
              fingers. The proposed method deals with a multi-class
              classification problem. Our machine learning strategy to solve
              this problem is built on an ensemble of one-class classifiers,
              each of which is dedicated to the prediction of the intention to
              move a specific finger. Regions of the brain that are sensitive
              to the movements of the fingers are identified and located. The
              average accuracy of the proposed EEG signal processing chain
              reached 81\% for five subjects. Unlike the majority of existing
              prototypes that allow only one single finger to be controlled and
              only one movement to be performed at a time, the system proposed
              will enable multiple fingers to perform movements simultaneously.
              Although the proposed system classifies five tasks, the obtained
              accuracy is too high compared with a binary classification
              system. The proposed system contributes to the advancement of a
              novel prosthetic solution that allows people with severe
              disabilities to perform daily tasks in an easy manner.",
  journal  = "Brain Sci",
  volume   =  10,
  number   =  12,
  pages    = "1--14",
  month    =  dec,
  year     =  2020,
  keywords = "Brain-computer interface; Decoding finger movement; EEG;
              Multi-class classification; Prosthetic finger;fastReach",
  language = "en"
}

@ARTICLE{Jain2020-dj,
  title     = "Designing Interactions Beyond Conscious Control: A New Model for
               Wearable Interfaces",
  author    = "Jain, Abhinandan and Horowitz, Adam Haar and Schoeller, Felix
               and Leigh, Sang-Won and Maes, Pattie and Sra, Misha",
  abstract  = "Recent research in psychology distinguishes levels of
               consciousness into a tripartite model - conscious, unconscious
               and metaconscious. HCI technologies largely focus on the
               conscious pathway for computer-to-human interaction, requiring
               explicit user attention and action. In contrast, the other two
               pathways provide opportunities to create new interfaces that can
               alter emotion, cognition and behavior without demands on
               attentional resources. These direct interfaces connect to
               cognitive processes that are in our perception but outside our
               conscious control. In this work, we feature two sub-categories,
               namely preconscious and metasomatic within the tripartite model
               of consciousness. Our goal is to provide a finer categorization
               of cognitive processes that can better help classify HCI
               research related to activating non-conscious cognitive pathways.
               We present the design of two wearable devices, MoveU and
               Frisson. From lessons learned during the iterative design
               process and the user studies, we present four design
               considerations that can be used to aid HCI researchers of future
               devices that influence the mind. With this work we aim to
               highlight that awareness of consciousness levels can be a
               valuable design element that can help to expand the range of
               computer-to-human interface devices we build.",
  journal   = "Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.",
  publisher = "Association for Computing Machinery",
  volume    =  4,
  number    =  3,
  pages     = "1--23",
  month     =  sep,
  year      =  2020,
  address   = "New York, NY, USA",
  keywords  = "design methods; interaction design; wearable
               computing;BCInt;fastReach;workshop\_reading\_material;Springer-Affordances\_in\_HCI;RP
               for HCI"
}

@ARTICLE{Krauledat2004-sb,
  title    = "Improving speed and accuracy of brain-computer interfaces using
              readiness potential features",
  author   = "Krauledat, M and Dornhege, G and Blankertz, B and Losch, F and
              Curio, G and M{\"u}ller, K-R",
  abstract = "To enhance human interaction with machines, research interest is
              growing to develop a 'brain-computer interface', which allows
              communication of a human with a machine only by use of brain
              signals. So far, the applicability of such an interface is
              strongly limited by low bit-transfer rates, slow response times
              and long training sessions for the subject. The Berlin
              Brain-Computer Interface (BBCI) project is guided by the idea to
              train a computer by advanced machine learning techniques both to
              improve classification performance and to reduce the need of
              subject training. In this paper we present two directions in
              which brain-computer interfacing can be enhanced by exploiting
              the lateralized readiness potential: (1) for establishing a rapid
              response BCI system that can predict the laterality of upcoming
              finger movements before EMG onset even in time critical contexts,
              and (2) to improve information transfer rates in the common BCI
              approach relying on imagined limb movements.",
  journal  = "Conf. Proc. IEEE Eng. Med. Biol. Soc.",
  volume   =  2004,
  pages    = "4511--4515",
  year     =  2004,
  keywords = "BCInt;fastReach",
  language = "en"
}

@INPROCEEDINGS{Meinel2015-zo,
  title     = "{EEG} band power predicts single-trial reaction time in a hand
               motor task",
  booktitle = "2015 7th International {IEEE/EMBS} Conference on Neural
               Engineering ({NER})",
  author    = "Meinel, Andreas and Casta{\~n}o-Candamil, Juan Sebastian and
               D{\"a}hne, Sven and Reis, Janine and Tangermann, Michael",
  abstract  = "The power of oscillatory brain sources can provide valuable
               information about trial-to-trial fluctuations considering the
               behavioural performance of subjects. Extracting such sources
               from electroencephalogram (EEG) recordings, however, proves to
               be difficult for most applications as the signal-to-noise ratio
               (SNR) in EEG typically is low. In an offline study with EEG data
               from three healthy subjects, we investigated the use of a
               recently introduced data-driven spatial filtering method called
               Source Power Comodulation (SPoC) [1]. Based on the
               trial-to-trial performance metric of a hand motor task, SPoC
               derives individually optimized linear spatial filters. They are
               optimized such that the resulting oscillatory signal component
               comodulates in band power with the performance metric at an
               increased SNR. Based on short intervals [-800; 0] ms prior to
               the go cue of $\approx$ 200 trials, we were able to identify
               individual oscillatory components. Their alpha band power
               comodulates with the reaction time (RT) during an isometric
               force control task of the hand. Using these components, it is
               possible to reach an average correlation of 0.19, with the best
               feature explaining up to 17\% of the RT variation between single
               trials.",
  volume    = "2015-July",
  pages     = "182--185",
  month     =  apr,
  year      =  2015,
  keywords  = "EEG; bandpower analysis; comodulation; single-trial analysis;
               spatial filter; visual-motor reaction time;
               Electroencephalography; Correlation; Visualization; Force;
               Decoding; Signal to noise ratio;fastReach"
}

@ARTICLE{Pereira2017-vm,
  title     = "{EEG} neural correlates of goal-directed movement intention",
  author    = "Pereira, Joana and Ofner, Patrick and Schwarz, Andreas and
               Sburlea, Andreea Ioana and M{\"u}ller-Putz, Gernot R",
  abstract  = "Using low-frequency time-domain electroencephalographic (EEG)
               signals we show, for the same type of upper limb movement, that
               goal-directed movements have different neural correlates than
               movements without a particular goal. In a reach-and-touch task,
               we explored the differences in the movement-related cortical
               potentials (MRCPs) between goal-directed and non-goal-directed
               movements. We evaluated if the detection of movement intention
               was influenced by the goal-directedness of the movement. In a
               single-trial classification procedure we found that
               classification accuracies are enhanced if there is a
               goal-directed movement in mind. Furthermore, by using the
               classifier patterns and estimating the corresponding brain
               sources, we show the importance of motor areas and the
               additional involvement of the posterior parietal lobule in the
               discrimination between goal-directed movements and
               non-goal-directed movements. We discuss next the potential
               contribution of our results on goal-directed movements to a more
               reliable brain-computer interface (BCI) control that facilitates
               recovery in spinal-cord injured or stroke end-users.",
  journal   = "Neuroimage",
  publisher = "Elsevier",
  volume    =  149,
  number    = "January",
  pages     = "129--140",
  month     =  apr,
  year      =  2017,
  keywords  = "Brain sources; Brain-computer interface (BCI);
               Electroencephalography (EEG); Goal-directed movement;
               Low-frequency; Movement-related cortical potential
               (MRCP);fastReach;RP for HCI;affordance I/O",
  language  = "en"
}

@INPROCEEDINGS{Ahmed2016-au,
  title     = "Reach out and touch me: effects of four distinct haptic
               technologies on affective touch in virtual reality",
  booktitle = "Proceedings of the 18th {ACM} International Conference on
               Multimodal Interaction",
  author    = "Ahmed, Imtiaj and Harjunen, Ville and Jacucci, Giulio and
               Hoggan, Eve and Ravaja, Niklas and Spap{\'e}, Michiel M",
  abstract  = "Virtual reality presents an extraordinary platform for
               multimodal communication. Haptic technologies have been shown to
               provide an important contribution to this by facilitating
               co-presence and allowing affective communication. However, the
               findings of the affective influences rely on studies that have
               used myriad different types of haptic technology, making it
               likely that some forms of tactile feedback are more efficient in
               communicating emotions than others. To find out whether this is
               true and which haptic technologies are most effective, we
               measured user experience during a communication scenario
               featuring an affective agent and interpersonal touch in virtual
               reality. Interpersonal touch was simulated using two types of
               vibrotactile actuators and two types of force feedback
               mechanisms. Self-reports of subjective experience of the agent's
               touch and emotions were obtained. The results revealed that,
               regardless of the agent's expression, force feedback actuators
               were rated as more natural and resulted in greater emotional
               interdependence and a stronger sense of co-presence than
               vibrotactile touch.",
  publisher = "Association for Computing Machinery",
  pages     = "341--348",
  series    = "ICMI '16",
  month     =  oct,
  year      =  2016,
  address   = "New York, NY, USA",
  keywords  = "Affective communication; Facial expressions; Haptic
               technologies; Virtual reality;fastReach",
  location  = "Tokyo, Japan"
}

@INPROCEEDINGS{Putze2020-bd,
  title      = "Platform for Studying {Self-Repairing} {Auto-Corrections} in
                Mobile Text Entry based on Brain Activity, Gaze, and Context",
  booktitle  = "Proceedings of the 2020 {CHI} Conference on Human Factors in
                Computing Systems",
  author     = "Putze, Felix and Ihrig, Tilman and Schultz, Tanja and
                Stuerzlinger, Wolfgang",
  abstract   = "Auto-correction is a standard feature of mobile text entry.
                While the performance of state-of-the-art auto-correct methods
                is usually relatively high, any errors that occur are
                cumbersome to repair, interrupt the flow of text entry, and
                challenge the user's agency over the process. In this paper, we
                describe a system that aims to automatically identify and
                repair auto-correction errors. This system comprises a
                multi-modal classifier for detecting auto-correction errors
                from brain activity, eye gaze, and context information, as well
                as a strategy to repair such errors by replacing the erroneous
                correction or suggesting alternatives. We integrated both parts
                in a generic Android component and thus present a research
                platform for studying self-repairing end-to-end systems. To
                demonstrate its feasibility, we performed a user study to
                evaluate the classification performance and usability of our
                approach.",
  publisher  = "Association for Computing Machinery",
  pages      = "1--13",
  series     = "CHI '20",
  month      =  apr,
  year       =  2020,
  address    = "New York, NY, USA",
  keywords   = "EEG; auto-correction; eye gaze; self-repair; text
                entry;fastReach;RP for HCI",
  conference = "CHI '20: CHI Conference on Human Factors in Computing Systems",
  location   = "Honolulu, HI, USA"
}

@ARTICLE{Kim2015-ml,
  title    = "Decoding {Three-Dimensional} Trajectory of Executed and Imagined
              Arm Movements From Electroencephalogram Signals",
  author   = "Kim, Jeong-Hun and Bie{\ss}mann, Felix and Lee, Seong-Whan",
  abstract = "Decoding motor commands from noninvasively measured neural
              signals has become important in brain-computer interface (BCI)
              research. Applications of BCI include neurorehabilitation after
              stroke and control of limb prostheses. Until now, most studies
              have tested simple movement trajectories in two dimensions by
              using constant velocity profiles. However, most real-world
              scenarios require much more complex movement trajectories and
              velocity profiles. In this study, we decoded motor commands in
              three dimensions from electroencephalography (EEG) recordings
              while the subjects either executed or observed/imagined complex
              upper limb movement trajectories. We compared the accuracy of
              simple linear methods and nonlinear methods. In line with
              previous studies our results showed that linear decoders are an
              efficient and robust method for decoding motor commands. However,
              while we took the same precautions as previous studies to
              suppress eye-movement related EEG contamination, we found that
              subtracting residual electro-oculogram activity from the EEG data
              resulted in substantially lower motor decoding accuracy for
              linear decoders. This effect severely limits the transfer of
              previous results to practical applications in which neural
              activation is targeted. We observed that nonlinear methods showed
              no such drop in decoding performance. Our results demonstrate
              that eye-movement related contamination of brain signals
              constitutes a severe problem for decoding motor signals from EEG
              data. These results are important for developing accurate
              decoders of motor signal from neural signals for use with
              BCI-based neural prostheses and neurorehabilitation in real-world
              scenarios.",
  journal  = "IEEE Trans. Neural Syst. Rehabil. Eng.",
  volume   =  23,
  number   =  5,
  pages    = "867--876",
  month    =  sep,
  year     =  2015,
  keywords = "Arm movement trajectory; Brain-computer interfaces (BCI);
              Electroencephalography (EEG); Kernel ridge regression; Upper limb
              rehabilitation;fastReach;affordance I/O;RP for HCI",
  language = "en"
}

@ARTICLE{Noel2017-hc,
  title     = "The spatial self in schizophrenia and autism spectrum disorder",
  author    = "Noel, Jean-Paul and Cascio, Carissa J and Wallace, Mark T and
               Park, Sohee",
  abstract  = "Schizophrenia (SZ) and autism spectrum disorder (ASD) have been
               both described as disorders of the self. However, the manner in
               which the sense of self is impacted in these disorders is
               strikingly different. In the current review, we propose that SZ
               and ASD lay at opposite extremes of a particular component of
               the representation of self; namely, self-location and the
               construct of peripersonal space. We evaluate emerging literature
               suggesting that while SZ individuals possess an extremely weak
               or variable bodily boundary between self and other, ASD patients
               possess a sharper self-other boundary. Furthermore, based on
               recent behavioral and neural network modeling findings, we
               propose that multisensory training focused on either sharpening
               (for SZ) or making shallower (for ASD) the self-other boundary
               may hold promise as an interventional tool in the treatment of
               these disorders.",
  journal   = "Schizophr. Res.",
  publisher = "Elsevier B.V.",
  volume    =  179,
  pages     = "8--12",
  month     =  jan,
  year      =  2017,
  keywords  = "Autism; Location; Multisensory; Peripersonal; Schizophrenia;
               Self;bodily self",
  language  = "en"
}

@ARTICLE{Tsakiris2017-oe,
  title     = "The multisensory basis of the self: From body to identity to
               others",
  author    = "Tsakiris, Manos",
  abstract  = "By grounding the self in the body, experimental psychology has
               taken the body as the starting point for a science of the self.
               One fundamental dimension of the bodily self is the sense of
               body ownership that refers to the special perceptual status of
               one's own body, the feeling that ?my body? belongs to me. The
               primary aim of this review article is to highlight recent
               advances in the study of body ownership and our understanding of
               the underlying neurocognitive processes in three ways. I first
               consider how the sense of body ownership has been investigated
               and elucidated in the context of multisensory integration.
               Beyond exteroception, recent studies have considered how this
               exteroceptively driven sense of body ownership can be linked to
               the other side of embodiment, that of the unobservable, yet
               felt, interoceptive body, suggesting that these two sides of
               embodiment interact to provide a unifying bodily self. Lastly,
               the multisensorial understanding of the self has been shown to
               have implications for our understanding of social relationships,
               especially in the context of self?other boundaries. Taken
               together, these three research strands motivate a unified model
               of the self inspired by current predictive coding models.",
  journal   = "Q. J. Exp. Psychol.",
  publisher = "SAGE Publications",
  volume    =  70,
  number    =  4,
  pages     = "597--609",
  month     =  apr,
  year      =  2017,
  keywords  = "Body awareness; Body ownership; Interoception; Multisensory;
               Self; Social cognition;bodily self"
}

@ARTICLE{Blanke2015-jo,
  title     = "Behavioral, Neural, and Computational Principles of Bodily
               {Self-Consciousness}",
  author    = "Blanke, Olaf and Slater, Mel and Serino, Andrea",
  abstract  = "Recent work in human cognitive neuroscience has linked
               self-consciousness to the processing of multisensory bodily
               signals (bodily self-consciousness [BSC]) in fronto-parietal
               cortex and more posterior temporo-parietal regions. We highlight
               the behavioral, neurophysiological, neuroimaging, and
               computational laws that subtend BSC in humans and non-human
               primates. We propose that BSC includes body-centered perception
               (hand, face, and trunk), based on the integration of
               proprioceptive, vestibular, and visual bodily inputs, and
               involves spatio-temporal mechanisms integrating multisensory
               bodily stimuli within peripersonal space (PPS). We develop four
               major constraints of BSC (proprioception, body-related visual
               information, PPS, and embodiment) and argue that the
               fronto-parietal and temporo-parietal processing of
               trunk-centered multisensory signals in PPS is of particular
               relevance for theoretical models and simulations of BSC and
               eventually of self-consciousness.",
  journal   = "Neuron",
  publisher = "Elsevier Inc.",
  volume    =  88,
  number    =  1,
  pages     = "145--166",
  month     =  oct,
  year      =  2015,
  keywords  = "bodily self;fastReach",
  language  = "en"
}

@ARTICLE{Guterstam2015-gq,
  title    = "Posterior cingulate cortex integrates the senses of self-location
              and body ownership",
  author   = "Guterstam, Arvid and Bj{\"o}rnsdotter, Malin and Gentile,
              Giovanni and Ehrsson, H Henrik",
  abstract = "The senses of owning a body and being localized somewhere in
              space are two key components of human self-consciousness. Despite
              a wealth of neurophysiological and neuroimaging research on the
              representations of the spatial environment in the parietal and
              medial temporal cortices, the relationship between body ownership
              and self-location remains unexplored. To investigate this
              relationship, we used a multisensory out-of-body illusion to
              manipulate healthy participants' perceived self-location, head
              direction, and sense of body ownership during high-resolution
              fMRI. Activity patterns in the hippocampus and the posterior
              cingulate, retrosplenial, and intraparietal cortices reflected
              the sense of self-location, whereas the sense of body ownership
              was associated with premotor-intraparietal activity. The
              functional interplay between these two sets of areas was mediated
              by the posterior cingulate cortex. These results extend our
              understanding of the role of the posterior parietal and medial
              temporal cortices in spatial cognition by demonstrating that
              these areas not only are important for ecological behaviors, such
              as navigation and perspective taking, but also support the
              perceptual representation of the bodily self in space. Our
              results further suggest that the posterior cingulate cortex has a
              key role in integrating the neural representations of
              self-location and body ownership.",
  journal  = "Curr. Biol.",
  volume   =  25,
  number   =  11,
  pages    = "1416--1425",
  month    =  jun,
  year     =  2015,
  keywords = "bodily self;alpha;fastReach;aritificial\_proprioception",
  language = "en"
}

@ARTICLE{Grivaz2017-ye,
  title     = "Common and distinct brain regions processing multisensory bodily
               signals for peripersonal space and body ownership",
  author    = "Grivaz, Petr and Blanke, Olaf and Serino, Andrea",
  abstract  = "We take the feeling that our body belongs to us for granted.
               However, recent research has shown that it is possible to alter
               the subjective sensation of body ownership (BO) by manipulating
               multisensory bodily inputs. Several frontal and parietal regions
               are known to specifically process multisensory cues presented
               close to the body, i.e., within the peripersonal space (PPS). It
               has been proposed that these PPS fronto-parietal regions also
               underlie BO. However, most previous studies investigated the
               brain mechanisms of either BO or of PPS processing separately
               and by using a variety of paradigms. Here, we conducted an
               extensive meta-analysis of functional neuroimaging studies to
               investigate PPS and BO processing in humans in order to: a)
               assess quantitatively where each one of these functions was
               individually processed in the brain; b) identify whether and
               where these processes shared common or engaged distinct brain
               mechanisms; c) characterize these areas in terms of whole-brain
               co-activation networks and functions, respectively. We
               identified (i) a bilateral PPS network including superior
               parietal, temporo-parietal and ventral premotor regions and (ii)
               a BO network including posterior parietal cortex (right
               intraparietal sulcus, IPS; and left IPS and superior parietal
               lobule, SPL), right ventral premotor cortex, and the left
               anterior insula. Co-activation maps related to both PPS and BO
               encompassed largely overlapping fronto-parietal networks, but
               whereas the PPS network was more frequently associated with
               sensorimotor tasks, the BO network was rather associated with
               attention and awareness tasks. Finally, the conjunction analysis
               showed that (iii) PPS and BO tasks anatomically overlapped only
               in two clusters located in the left parietal cortex (dorsally at
               the intersection between the SPL, the IPS and area 2 and
               ventrally between areas 2 and IPS). Distinct activations were
               located for PPS at the temporo-parietal junction and for BO in
               the anterior insula. These results in PPS and BO and provide
               evidence-based insight about the overlap of the two processes in
               the IPS region and the extensive connectivity between the two
               associated co-activation networks. They also show significant
               dissociations, with PPS fronto-parietal areas located more
               proximal to the central sulcus than BO areas. Such anatomical
               distinction may also reflect the different functions of the two
               processes, whereby PPS areas underlie a multisensory-motor
               interface for body-objects interaction and BO areas being
               involved in bodily awareness and self-consciousness.",
  journal   = "Neuroimage",
  publisher = "Elsevier",
  volume    =  147,
  number    = "iii",
  pages     = "602--618",
  month     =  feb,
  year      =  2017,
  keywords  = "ALE meta-analysis; Bodily self-consciousness; Body ownership;
               Multisensory integration; PET; Peripersonal space; fMRI;
               multisensory integration;fastReach",
  language  = "en"
}

@ARTICLE{Pfurtscheller2010-ij,
  title    = "The hybrid {BCI}",
  author   = "Pfurtscheller, Gert and Allison, Brendan Z and Brunner, Clemens
              and Bauernfeind, Gunther and Solis-Escalante, Teodoro and
              Scherer, Reinhold and Zander, Thorsten O and Mueller-Putz, Gernot
              and Neuper, Christa and Birbaumer, Niels",
  abstract = "Nowadays, everybody knows what a hybrid car is. A hybrid car
              normally has two engines to enhance energy efficiency and reduce
              CO2 output. Similarly, a hybrid brain-computer interface (BCI) is
              composed of two BCIs, or at least one BCI and another system. A
              hybrid BCI, like any BCI, must fulfill the following four
              criteria: (i) the device must rely on signals recorded directly
              from the brain; (ii) there must be at least one recordable brain
              signal that the user can intentionally modulate to effect
              goal-directed behaviour; (iii) real time processing; and (iv) the
              user must obtain feedback. This paper introduces hybrid BCIs that
              have already been published or are in development. We also
              introduce concepts for future work. We describe BCIs that
              classify two EEG patterns: one is the event-related
              (de)synchronisation (ERD, ERS) of sensorimotor rhythms, and the
              other is the steady-state visual evoked potential (SSVEP). Hybrid
              BCIs can either process their inputs simultaneously, or operate
              two systems sequentially, where the first system can act as a
              ``brain switch''. For example, we describe a hybrid BCI that
              simultaneously combines ERD and SSVEP BCIs. We also describe a
              sequential hybrid BCI, in which subjects could use a brain switch
              to control an SSVEP-based hand orthosis. Subjects who used this
              hybrid BCI exhibited about half the false positives encountered
              while using the SSVEP BCI alone. A brain switch can also rely on
              hemodynamic changes measured through near-infrared spectroscopy
              (NIRS). Hybrid BCIs can also use one brain signal and a different
              type of input. This additional input can be an
              electrophysiological signal such as the heart rate, or a signal
              from an external device such as an eye tracking system.",
  journal  = "Front. Neurosci.",
  volume   =  4,
  number   = "April",
  pages    = "30",
  month    =  apr,
  year     =  2010,
  keywords = "brain; computer interface; event-related desynchronization;
              hybrid bci; motor imagery; ssvep; brain--computer
              interface;fastReach",
  language = "en"
}

@ARTICLE{Norman2021-vt,
  title     = "Single-trial decoding of movement intentions using functional
               ultrasound neuroimaging",
  author    = "Norman, Sumner L and Maresca, David and Christopoulos, Vassilios
               N and Griggs, Whitney S and Demene, Charlie and Tanter, Mickael
               and Shapiro, Mikhail G and Andersen, Richard A",
  abstract  = "New technologies are key to understanding the dynamic activity
               of neural circuits and systems in the brain. Here, we show that
               a minimally invasive approach based on ultrasound can be used to
               detect the neural correlates of movement planning, including
               directions and effectors. While non-human primates (NHPs)
               performed memory-guided movements, we used functional ultrasound
               (fUS) neuroimaging to record changes in cerebral blood volume
               with 100 $\mu$m resolution. We recorded from outside the dura
               above the posterior parietal cortex, a brain area important for
               spatial perception, multisensory integration, and movement
               planning. We then used fUS signals from the delay period before
               movement to decode the animals' intended direction and effector.
               Single-trial decoding is a prerequisite to brain-machine
               interfaces, a key application that could benefit from this
               technology. These results are a critical step in the development
               of neuro-recording and brain interface tools that are less
               invasive, high resolution, and scalable.",
  journal   = "Neuron",
  publisher = "Elsevier Inc.",
  volume    =  109,
  number    =  9,
  pages     = "1554--1566.e4",
  month     =  may,
  year      =  2021,
  keywords  = "Brain-machine interface; Non-human primate; Posterior parietal
               Cortex; Reach; Saccade; functional ultrasound neuroimaging;
               movement planning; single-trial decoding;fastReach;RP for
               HCI;affordance I/O",
  language  = "en"
}

@ARTICLE{Schultze-Kraft2021-cu,
  title    = "Suppress Me if You Can: Neurofeedback of the Readiness Potential",
  author   = "Schultze-Kraft, Matthias and Jonany, Vincent and Binns, Thomas
              Samuel and Soch, Joram and Blankertz, Benjamin and Haynes,
              John-Dylan",
  abstract = "Voluntary movements are usually preceded by a slow,
              negative-going brain signal over motor areas, the so-called
              readiness potential (RP). To date, the exact nature and causal
              role of the RP in movement preparation have remained heavily
              debated. Although the RP is influenced by several motorical and
              cognitive factors, it has remained unclear whether people can
              learn to exert mental control over their RP, for example, by
              deliberately suppressing it. If people were able to initiate
              spontaneous movements without eliciting an RP, this would
              challenge the idea that the RP is a necessary stage of the causal
              chain leading up to a voluntary movement. We tested the ability
              of participants to control the magnitude of their RP in a
              neurofeedback experiment. Participants performed self-initiated
              movements, and after every movement, they were provided with
              immediate feedback about the magnitude of their RP. They were
              asked to find a strategy to perform voluntary movements such that
              the RPs were as small as possible. We found no evidence that
              participants were able to to willfully modulate or suppress their
              RPs while still eliciting voluntary movements. This suggests that
              the RP might be an involuntary component of voluntary action over
              which people cannot exert conscious control.",
  journal  = "eNeuro",
  volume   =  8,
  number   =  2,
  pages    = "1--11",
  month    =  mar,
  year     =  2021,
  keywords = "Conscious control; EEG; Neurofeedback; Readiness potential;
              Voluntary movement;BCInt;fastReach;RP for HCI",
  language = "en"
}

@ARTICLE{Kieliba2021-qg,
  title    = "Robotic hand augmentation drives changes in neural body
              representation",
  author   = "Kieliba, Paulina and Clode, Danielle and Maimon-Mor, Roni O and
              Makin, Tamar R",
  abstract = "Humans have long been fascinated by the opportunities afforded
              through augmentation. This vision not only depends on
              technological innovations but also critically relies on our
              brain's ability to learn, adapt, and interface with augmentation
              devices. Here, we investigated whether successful motor
              augmentation with an extra robotic thumb can be achieved and what
              its implications are on the neural representation and function of
              the biological hand. Able-bodied participants were trained to use
              an extra robotic thumb (called the Third Thumb) over 5 days,
              including both lab-based and unstructured daily use. We
              challenged participants to complete normally bimanual tasks using
              only the augmented hand and examined their ability to develop
              hand-robot interactions. Participants were tested on a variety of
              behavioral and brain imaging tests, designed to interrogate the
              augmented hand's representation before and after the training.
              Training improved Third Thumb motor control, dexterity, and
              hand-robot coordination, even when cognitive load was increased
              or when vision was occluded. It also resulted in increased sense
              of embodiment over the Third Thumb. Consequently, augmentation
              influenced key aspects of hand representation and motor control.
              Third Thumb usage weakened natural kinematic synergies of the
              biological hand. Furthermore, brain decoding revealed a mild
              collapse of the augmented hand's motor representation after
              training, even while the Third Thumb was not worn. Together, our
              findings demonstrate that motor augmentation can be readily
              achieved, with potential for flexible use, reduced cognitive
              reliance, and increased sense of embodiment. Yet, augmentation
              may incur changes to the biological hand representation. Such
              neurocognitive consequences are crucial for successful
              implementation of future augmentation technologies.",
  journal  = "Sci Robot",
  volume   =  6,
  number   =  54,
  month    =  may,
  year     =  2021,
  keywords = "fastReach",
  language = "en"
}

@ARTICLE{Raisamo2019-ac,
  title    = "Human augmentation: Past, present and future",
  author   = "Raisamo, Roope and Rakkolainen, Ismo and Majaranta, P{\"a}ivi and
              Salminen, Katri and Rantala, Jussi and Farooq, Ahmed",
  abstract = "Human augmentation is a field of research that aims to enhance
              human abilities through medicine or technology. This has
              historically been achieved by consuming chemical substances that
              improve a selected ability or by installing implants which
              require medical operations. Both of these methods of augmentation
              can be invasive. Augmented abilities have also been achieved with
              external tools, such as eyeglasses, binoculars, microscopes or
              highly sensitive microphones. Lately, augmented reality and
              multimodal interaction technologies have enabled non-invasive
              ways to augment human. In this article, we first discuss the
              field and related terms. We provide relevant definitions based on
              the present understanding of the field. This is followed by a
              summary of existing work in augmented senses, action, and
              cognition. Our contribution to the future includes a model for
              wearable augmentation. In addition, we present a call for
              research to realize this vision. Then, we discuss future human
              abilities. Wearable technologies may act as mediators for human
              augmentation, in the same manner as eyeglasses once
              revolutionized human vision. Non-invasive and easy-to-use
              wearable extensions will enable lengthening the active life for
              aging citizens or supporting the full inclusion of people with
              special needs in society, but there are also potential problems.
              Therefore, we conclude by discussing ethical and societal issues:
              privacy, social manipulation, autonomy and side effects,
              accessibility, safety and balance, and unpredictable future.",
  journal  = "Int. J. Hum. Comput. Stud.",
  volume   =  131,
  pages    = "131--143",
  month    =  nov,
  year     =  2019,
  keywords = "Human augmentation; Augmented reality; Wearable computing;
              Multimodal interaction; Crossmodal interaction; Augmented senses;
              Augmented action; Augmented cognition; Interaction
              paradigms;fastReach;\_Vision;Springer-Affordances\_in\_HCI"
}

@BOOK{Huber2018-uw,
  title     = "Assistive Augmentation",
  editor    = "Huber, Jochen and Shilkrot, Roy and Maes, Pattie and
               Nanayakkara, Suranga",
  publisher = "Springer, Singapore",
  year      =  2018,
  keywords  = "Super interesting;RP for HCI;proxEMG;fastReach;affordance I/O"
}

@ARTICLE{Farina2021-zj,
  title    = "Toward higher-performance bionic limbs for wider clinical use",
  author   = "Farina, Dario and Vujaklija, Ivan and Br{\aa}nemark, Rickard and
              Bull, Anthony M J and Dietl, Hans and Graimann, Bernhard and
              Hargrove, Levi J and Hoffmann, Klaus-Peter and Huang, He Helen
              and Ingvarsson, Thorvaldur and Janusson, Hilmar Bragi and
              Kristj{\'a}nsson, Kristleifur and Kuiken, Todd and Micera,
              Silvestro and Stieglitz, Thomas and Sturma, Agnes and Tyler,
              Dustin and Weir, Richard F Ff and Aszmann, Oskar C",
  abstract = "Most prosthetic limbs can autonomously move with dexterity, yet
              they are not perceived by the user as belonging to their own
              body. Robotic limbs can convey information about the environment
              with higher precision than biological limbs, but their actual
              performance is substantially limited by current technologies for
              the interfacing of the robotic devices with the body and for
              transferring motor and sensory information bidirectionally
              between the prosthesis and the user. In this Perspective, we
              argue that direct skeletal attachment of bionic devices via
              osseointegration, the amplification of neural signals by targeted
              muscle innervation, improved prosthesis control via implanted
              muscle sensors and advanced algorithms, and the provision of
              sensory feedback by means of electrodes implanted in peripheral
              nerves, should all be leveraged towards the creation of a new
              generation of high-performance bionic limbs. These technologies
              have been clinically tested in humans, and alongside mechanical
              redesigns and adequate rehabilitation training should facilitate
              the wider clinical use of bionic limbs.",
  journal  = "Nat Biomed Eng",
  month    =  may,
  year     =  2021,
  keywords = "fastReach;affordance I/O",
  language = "en"
}

@ARTICLE{Valeriani2021-ds,
  title    = "Editorial: Neurotechnologies for Human Augmentation",
  author   = "Valeriani, Davide and Ayaz, Hasan and Kosmyna, Nataliya and Poli,
              Riccardo and Maes, Pattie",
  journal  = "Front. Neurosci.",
  volume   =  15,
  pages    = "1503",
  year     =  2021,
  keywords = "affordance I/O;fastReach"
}

@ARTICLE{Trov2021-vp,
  title    = "{Movement-Preceding} Neural Activity under Parametrically Varying
              Levels of Time Pressure",
  author   = "Trov, Bianca",
  pages    = "1--26",
  year     =  2021,
  keywords = "BCInt;fastReach;RP for HCI"
}

@ARTICLE{Gerrits2017-lf,
  title    = "Predicting movement intent in real-time: From brain to subjective
              experience",
  author   = "Gerrits, Anne",
  number   = "February",
  year     =  2017,
  keywords = "fastReach;RP for HCI;affordance I/O"
}

@ARTICLE{Gatti2021-ti,
  title    = "Decoding kinetic features of hand motor preparation from
              single-trial {EEG} using convolutional neural networks",
  author   = "Gatti, Ramiro and Atum, Yanina and Schiaffino, Luciano and
              Jochumsen, Mads and Biurrun Manresa, Jos{\'e}",
  abstract = "Building accurate movement decoding models from brain signals is
              crucial for many biomedical applications. Predicting specific
              movement features, such as speed and force, before movement
              execution may provide additional useful information at the
              expense of increasing the complexity of the decoding problem.
              Recent attempts to predict movement speed and force from the
              electroencephalogram (EEG) achieved classification accuracies at
              or slightly above chance levels, highlighting the need for more
              accurate prediction strategies. Thus, the aims of this study were
              to accurately predict hand movement speed and force from
              single-trial EEG signals and to decode neurophysiological
              information of motor preparation from the prediction strategies.
              To these ends, a decoding model based on convolutional neural
              networks (ConvNets) was implemented and compared against other
              state-of-the-art prediction strategies, such as support vector
              machines and decision trees. ConvNets outperformed the other
              prediction strategies, achieving an overall accuracy of 84\% in
              the classification of two different levels of speed and force
              (four-class classification) from pre-movement single-trial EEG
              (100 ms and up to 1,600 ms prior to movement execution).
              Furthermore, an analysis of the ConvNet architectures suggests
              that the network performs a complex spatiotemporal integration of
              EEG data to optimize classification accuracy. These results show
              that movement speed and force can be accurately predicted from
              single-trial EEG, and that the prediction strategies may provide
              useful neurophysiological information about motor preparation.",
  journal  = "Eur. J. Neurosci.",
  volume   =  53,
  number   =  2,
  pages    = "556--570",
  month    =  jan,
  year     =  2021,
  keywords = "brain computer interface; deep learning; movement prediction;
              multi-class classification; neural
              engineering;fastReach;affordance I/O",
  language = "en"
}
