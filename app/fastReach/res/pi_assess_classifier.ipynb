{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preconscious Augmentation\n",
    "\n",
    "This script trains the classifier for a brain-computer interface that controls electrical muscle stimulation in the preconscious augmentation experiment.\n",
    "The functions used to build the feature vectors are the same that are used for the online application and are found in 'bci_funcs'\n",
    "\n",
    "A two class linear discriminant model is fitted to idle and pre-movement EEG training data. The model and a channel selection is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pID = 2\n",
    "pID = 'sub-0' + \"%02d\" % (pID)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "import scipy.io\n",
    "from bci_funcs import windowed_mean, base_correct, drop_baseline\n",
    "import mne\n",
    "\n",
    "path = '/Volumes/projects/Lukas_Gehrke/2021-fastReach/data/study/eeglab2python/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/projects/Lukas_Gehrke/2021-fastReach/data/study/eeglab2python/sub-002/pre_move_EMS1.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:39\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m     \u001b[39m# Probably \"not found\"\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/projects/Lukas_Gehrke/2021-fastReach/data/study/eeglab2python/sub-002/pre_move_EMS1.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lukasgehrke/Documents/publications/2021-fastReach/app/fastReach/pi_assess_classifier.ipynb Cell 6\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukasgehrke/Documents/publications/2021-fastReach/app/fastReach/pi_assess_classifier.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m condition_names \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mBaseline\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEMS1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEMS2\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukasgehrke/Documents/publications/2021-fastReach/app/fastReach/pi_assess_classifier.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m condition \u001b[39min\u001b[39;00m condition_names:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lukasgehrke/Documents/publications/2021-fastReach/app/fastReach/pi_assess_classifier.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     tmp_move \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mloadmat(path\u001b[39m+\u001b[39;49mpID\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/pre_move_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mcondition\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.mat\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukasgehrke/Documents/publications/2021-fastReach/app/fastReach/pi_assess_classifier.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     tmp_idle \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mloadmat(path\u001b[39m+\u001b[39mpID\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/idle_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mcondition\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lukasgehrke/Documents/publications/2021-fastReach/app/fastReach/pi_assess_classifier.ipynb#W5sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     move\u001b[39m.\u001b[39mappend(tmp_move[\u001b[39m'\u001b[39m\u001b[39mpre_move\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:224\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39mLoad MATLAB file.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39m    3.14159265+3.14159265j])\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    223\u001b[0m variable_names \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mvariable_names\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 224\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    225\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    226\u001b[0m     matfile_dict \u001b[39m=\u001b[39m MR\u001b[39m.\u001b[39mget_variables(variable_names)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.16/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:17\u001b[0m, in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m@contextmanager\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_context\u001b[39m(file_like, appendmat, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     f, opened \u001b[39m=\u001b[39m _open_file(file_like, appendmat, mode)\n\u001b[1;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[39myield\u001b[39;00m f\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/scipy/io/matlab/_mio.py:45\u001b[0m, in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mif\u001b[39;00m appendmat \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m file_like\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     44\u001b[0m         file_like \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.mat\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_like, mode), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m     48\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mReader needs file name or open file-like object\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     49\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/projects/Lukas_Gehrke/2021-fastReach/data/study/eeglab2python/sub-002/pre_move_EMS1.mat'"
     ]
    }
   ],
   "source": [
    "chans = np.array(pd.read_csv(path+pID+'/sel_chans.csv', header=None)).flatten()\n",
    "chans = chans - 1 # Matlab to python indexing\n",
    "filename = path+pID+'/chans_'+pID+'_eeg.sav'\n",
    "pickle.dump(chans, open(filename, 'wb'))\n",
    "\n",
    "move = []\n",
    "idle = []\n",
    "conditions = []\n",
    "classes = []\n",
    "condition_names = ['Baseline', 'EMS1', 'EMS2']\n",
    "\n",
    "for condition in condition_names:\n",
    "    tmp_move = scipy.io.loadmat(path+pID+'/pre_move_'+condition+'.mat')\n",
    "    tmp_idle = scipy.io.loadmat(path+pID+'/idle_'+condition+'.mat')\n",
    "\n",
    "    move.append(tmp_move['pre_move'])\n",
    "    idle.append(tmp_idle['idle'])\n",
    "\n",
    "    # conditions\n",
    "    conditions.append(np.array([condition]*len(tmp_move['pre_move']) + [condition]*len(tmp_idle['idle'])))\n",
    "\n",
    "    # classes\n",
    "    classes.append(np.array([1]*len(tmp_move['pre_move']) + [0]*len(tmp_idle['idle'])))\n",
    "\n",
    "design = pd.DataFrame({'condition': np.concatenate(conditions), 'class': np.concatenate(classes)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(move, axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = 10\n",
    "baseline_ix = 1\n",
    "\n",
    "idle = idle['idle'][chans,:,:]\n",
    "pre_move = pre_move['pre_move'][chans,:,:]\n",
    "\n",
    "tmp_idle_means = np.zeros((idle.shape[2], len(chans), windows))\n",
    "tmp_pre_move_means = np.zeros((pre_move.shape[2], len(chans), windows))\n",
    "\n",
    "idle_means = np.zeros((idle.shape[2], idle.shape[0] * (windows)))\n",
    "pre_move_means = np.zeros((pre_move.shape[2], pre_move.shape[0] * (windows)))\n",
    "\n",
    "baseline = 250/10 # 100 ms baseline\n",
    "\n",
    "for trial_ix in range(0, pre_move.shape[2]):\n",
    "    tmp = base_correct(pre_move[:,:,trial_ix], baseline-1)\n",
    "    tmp_pre_move_means[trial_ix,:,:] = windowed_mean(tmp, windows = windows)\n",
    "    pre_move_means[trial_ix, :] = tmp_pre_move_means[trial_ix,:,:].flatten()\n",
    "\n",
    "for trial_ix in range(0, idle.shape[2]):\n",
    "    tmp = base_correct(idle[:,:,trial_ix], baseline-1)\n",
    "    tmp_idle_means[trial_ix, :, :] = windowed_mean(tmp, windows = windows)\n",
    "    idle_means[trial_ix, :] = tmp_idle_means[trial_ix,:,:].flatten()\n",
    "\n",
    "data = np.concatenate((pre_move_means, idle_means), axis = 0)\n",
    "\n",
    "# classes\n",
    "pre_move_class = np.ones((pre_move_means.shape[0], 1))\n",
    "idle_class = np.zeros((idle_means.shape[0], 1))\n",
    "classes = np.concatenate((pre_move_class, idle_class)).ravel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting ERPs and Scalp Maps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windowed Means as ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plots individual participants\n",
    "chans_names = pd.read_csv(path+pID+'/sel_chans_names.csv')\n",
    "\n",
    "# erp\n",
    "for c_ix in range(0, len(chans)):\n",
    "        \n",
    "    idle_c = tmp_pre_move_means[:,c_ix,:]\n",
    "    pre_move_c = tmp_idle_means[:,c_ix,:]\n",
    "    idle_c = pd.DataFrame(idle_c)\n",
    "    pre_move_c = pd.DataFrame(pre_move_c)\n",
    "\n",
    "    condition = pd.DataFrame(classes, columns=['class']).astype('string')\n",
    "    condition['class'].replace({'0.0': 'idle', '1.0': 'pre movement'}, inplace=True)\n",
    "\n",
    "    erp = pd.concat([pre_move_c, idle_c], axis=0).reset_index(drop=True)\n",
    "    erp_class_cz = pd.concat([condition['class'], erp], axis=1)\n",
    "\n",
    "    with sns.plotting_context('paper', font_scale = 1.8):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(9,5))\n",
    "        fig.patch.set_alpha(1)\n",
    "        sns.despine() #bottom=True, left=True \n",
    "\n",
    "        data_long = pd.melt(erp_class_cz, id_vars='class', var_name='timepoint', value_name='µV', col_level=None, ignore_index=True)\n",
    "\n",
    "        # adjust time axis\n",
    "        # data_long['timepoint'] = (((1/250) * (data_long[\"timepoint\"].astype(int)))*1000) - 1000\n",
    "\n",
    "        # plot\n",
    "        ax = sns.lineplot(data = data_long, x = 'timepoint', y = 'µV', hue = 'class')\n",
    "        ax.set(xlabel='Time (ms)', ylabel='µV', title=chans_names.Var1[chans[c_ix]])\n",
    "\n",
    "        fig.savefig(path + pID + '/erp/feats_' + chans_names.Var1[chans[c_ix]] + '.png', format='png', transparent=False, bbox_inches='tight', dpi=300)\n",
    "        fig.savefig(path + pID + '/erp/feats_' + chans_names.Var1[chans[c_ix]] + '.eps', format='eps', transparent=True, bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All samples ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save plots individual participants\n",
    "chans_names = pd.read_csv(path+pID+'/sel_chans_names.csv')\n",
    "\n",
    "# # erp\n",
    "# for c_ix in range(0, len(chans)):\n",
    "        \n",
    "#     idle_c = idle[c_ix,:,:] - np.mean(idle[c_ix,:24,:], axis = 0)\n",
    "#     pre_move_c = pre_move[c_ix,:,:] - np.mean(pre_move[c_ix,:24,:], axis = 0)\n",
    "#     idle_c = pd.DataFrame(idle_c.T)\n",
    "#     pre_move_c = pd.DataFrame(pre_move_c.T)\n",
    "\n",
    "#     condition = pd.DataFrame(classes, columns=['class']).astype('string')\n",
    "#     condition['class'].replace({'0.0': 'idle', '1.0': 'pre movement'}, inplace=True)\n",
    "\n",
    "#     erp = pd.concat([pre_move_c, idle_c], axis=0).reset_index(drop=True)\n",
    "#     erp_class_cz = pd.concat([condition['class'], erp], axis=1)\n",
    "\n",
    "#     with sns.plotting_context('paper', font_scale = 1.8):\n",
    "#         fig, ax = plt.subplots(1, 1, figsize=(9,5))\n",
    "#         fig.patch.set_alpha(1)\n",
    "#         sns.despine() #bottom=True, left=True \n",
    "\n",
    "#         data_long = pd.melt(erp_class_cz, id_vars='class', var_name='timepoint', value_name='µV', col_level=None, ignore_index=True)\n",
    "\n",
    "#         # adjust time axis\n",
    "#         data_long['timepoint'] = (((1/250) * (data_long[\"timepoint\"].astype(int)))*1000) - 1000\n",
    "\n",
    "#         # plot\n",
    "#         ax = sns.lineplot(data = data_long, x = 'timepoint', y = 'µV', hue = 'class')\n",
    "#         ax.set(xlabel='Time (ms)', ylabel='µV', title=chans_names.Var1[chans[c_ix]])\n",
    "\n",
    "#         fig.savefig(path + pID + '/erp/' + chans_names.Var1[chans[c_ix]] + '.png', format='png', transparent=False, bbox_inches='tight', dpi=300)\n",
    "#         fig.savefig(path + pID + '/erp/' + chans_names.Var1[chans[c_ix]] + '.eps', format='eps', transparent=True, bbox_inches='tight', dpi=300)\n",
    "\n",
    "# features, for one channel?\n",
    "\n",
    "# scalp topographies\n",
    "channel_labels = chans_names['Var1'].values.tolist()\n",
    "channel_labels = channel_labels[0:-1]\n",
    "eog_ix = channel_labels.index('VEOG')\n",
    "chans_types = ['eeg'] * channel_labels.__len__()\n",
    "chans_types[eog_ix] = 'eog'\n",
    "info = mne.create_info(channel_labels, ch_types=chans_types, sfreq=250)\n",
    "easycap_montage = mne.channels.make_standard_montage('easycap-M1')\n",
    "\n",
    "pre_move = scipy.io.loadmat(path+pID+'/pre_move.mat')\n",
    "pre_move = pre_move['pre_move'].mean(axis=2)\n",
    "pre_move = pre_move.T - pre_move[:,0:24].mean(axis=1)\n",
    "pre_move = pre_move.T\n",
    "\n",
    "raw = mne.EvokedArray(pre_move, info, tmin=-1)\n",
    "raw.set_montage(easycap_montage)\n",
    "\n",
    "# raw.pick_channels(chans_names.Var1[chans].values.tolist())\n",
    "\n",
    "times = np.arange(-1, 0, 0.1)\n",
    "fig = raw.plot_topomap(times, ch_type='eeg', time_unit='s', show_names=False)\n",
    "fig.savefig(path + pID + '/topomap_pre_move.png', format='png', transparent=False, bbox_inches='tight', dpi=300)\n",
    "fig.savefig(path + pID + '/topomap_pre_move.eps', format='eps', transparent=True, bbox_inches='tight', dpi=300)\n",
    "\n",
    "# idle = scipy.io.loadmat(path+pID+'/idle.mat')\n",
    "# idle = idle['idle'].mean(axis=2)\n",
    "# idle = idle.T - idle[:,0:24].mean(axis=1)\n",
    "# # idle = idle[24:,:].T\n",
    "\n",
    "# raw = mne.EvokedArray(idle, info, tmin=-1)\n",
    "# raw.set_montage(easycap_montage)\n",
    "\n",
    "# # raw.pick_channels(chans_names.Var1[chans].values.tolist())\n",
    "\n",
    "# times = np.arange(-1, 0, 0.1)\n",
    "# fig = raw.plot_topomap(times) #, [.1], ch_type='eeg', time_unit='s', show_names=False)\n",
    "# fig.savefig(path + pID + '/topomap_idle.png', format='png', transparent=False, bbox_inches='tight', dpi=300)\n",
    "# fig.savefig(path + pID + '/topomap_idle.eps', format='eps', transparent=True, bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Save and Evaluate Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load experiment data that the classifier has not seen\n",
    "\n",
    "pre_move_ems1 = scipy.io.loadmat(path+pID+'/pre_move_EMS1.mat')\n",
    "idle_ems1 = scipy.io.loadmat(path+pID+'/idle_EMS1.mat')\n",
    "\n",
    "idle_ems1 = idle_ems1['idle'][chans,:,:]\n",
    "pre_move_ems1 = pre_move_ems1['pre_move'][chans,:,:]\n",
    "\n",
    "pre_move_ems1_means = np.zeros((pre_move_ems1.shape[2], pre_move_ems1.shape[0] * (windows)))\n",
    "pre_move_ems1_class = np.ones((pre_move_ems1_means.shape[0], 1))\n",
    "\n",
    "for trial_ix in range(0, pre_move_ems1.shape[2]):\n",
    "    # tmp = base_correct(windowed_mean(pre_move_ems1[:,:,trial_ix], windows = windows))\n",
    "    # pre_move_ems1_means[trial_ix, :] = drop_baseline(tmp, baseline_ix).flatten()\n",
    "    tmp = base_correct(pre_move_ems1[:,:,trial_ix], baseline-1)\n",
    "    pre_move_ems1_means[trial_ix, :] = windowed_mean(tmp, windows = windows).flatten()\n",
    "\n",
    "idle_ems1_means = np.zeros((idle_ems1.shape[2], idle_ems1.shape[0] * (windows)))\n",
    "idle_ems1_class = np.zeros((idle_ems1_means.shape[0], 1))\n",
    "\n",
    "for trial_ix in range(0, idle_ems1.shape[2]):\n",
    "    # tmp = base_correct(windowed_mean(idle_ems1[:,:,trial_ix], windows = windows))\n",
    "    # idle_ems1_means[trial_ix, :] = drop_baseline(tmp, baseline_ix).flatten()\n",
    "    tmp = base_correct(idle_ems1[:,:,trial_ix], baseline-1)\n",
    "    idle_ems1_means[trial_ix, :] = windowed_mean(tmp, windows = windows).flatten()\n",
    "\n",
    "data_ems1 = np.concatenate((pre_move_ems1_means, idle_ems1_means), axis = 0)\n",
    "classes_ems1 = np.concatenate((pre_move_ems1_class, idle_ems1_class)).ravel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LDA(solver='eigen', shrinkage='auto')\n",
    "clf.fit(data, classes)\n",
    "\n",
    "kfolds = KFold(n_splits=5, random_state=1, shuffle=True) \n",
    "cv_results = cross_val_score(clf, data, classes, cv=kfolds)\n",
    "print(cv_results.mean())\n",
    "print(cv_results.std())\n",
    "\n",
    "filename = path+pID+'/model_'+pID+'_eeg.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Patterns and Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.decoding import LinearModel\n",
    "\n",
    "chans_names = pd.read_csv(path+pID+'/sel_chans_names.csv')\n",
    "channel_labels = chans_names['Var1'].values.tolist()\n",
    "channel_labels = channel_labels[0:-1]\n",
    "channel_labels = np.array(channel_labels)[chans].tolist()\n",
    "chans_types = ['eeg'] * channel_labels.__len__()\n",
    "\n",
    "info = mne.create_info(channel_labels, ch_types=chans_types, sfreq=10)\n",
    "easycap_montage = mne.channels.make_standard_montage('easycap-M1')\n",
    "times = np.arange(-1, 0, 0.1)\n",
    "\n",
    "# create a linear model with LogisticRegression\n",
    "model = LinearModel(clf)\n",
    "model.fit(data, classes)\n",
    "\n",
    "# Extract and plot spatial filters and spatial patterns\n",
    "for name, coef in (('patterns', model.patterns_), ('filters', model.filters_)):\n",
    "    # We fitted the linear model onto Z-scored data. To make the filters\n",
    "    # interpretable, we must reverse this normalization step\n",
    "    # coef = scaler.inverse_transform([coef])[0]\n",
    "\n",
    "    # The data was vectorized to fit a single model across all time points and\n",
    "    # all channels. We thus reshape it:\n",
    "    coef = coef.reshape(len(chans), -1)\n",
    "\n",
    "    # Plot\n",
    "    evoked = mne.EvokedArray(coef, info, tmin=-1)\n",
    "    evoked.set_montage(easycap_montage)\n",
    "\n",
    "    fig = evoked.plot_topomap(times)\n",
    "    fig.suptitle(f'MEG {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram LDA scores\n",
    "clf.fit(data, classes)\n",
    "\n",
    "lda_scores = clf.transform(data)\n",
    "\n",
    "df_to_plot = pd.DataFrame()\n",
    "df_to_plot['scores'] = pd.DataFrame(lda_scores)\n",
    "df_to_plot['classes'] = pd.DataFrame(classes)\n",
    "\n",
    "with sns.plotting_context('paper', font_scale = 1.8):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9,5))\n",
    "    fig.patch.set_alpha(1)\n",
    "    sns.despine() #bottom=True, left=True \n",
    "\n",
    "    sns.histplot(data=df_to_plot, x='scores', hue=classes, kde=True)\n",
    "\n",
    "    ax.set(xlabel='LDA score', ylabel='Frequency', title='Histogram of LDA scores')\n",
    "    ax.legend(['pre movement', 'idle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(data, classes)\n",
    "probs = np.round(clf.predict_proba(idle_ems1_means)[:,0],2)\n",
    "# probs = np.round(clf.predict_proba(pre_move_ems1_means)[:,1],2)\n",
    "# probs = np.round(clf.predict_proba(pre_move_means)[:,1],2)\n",
    "# probs = np.round(clf.predict_proba(idle_means)[:,0],2)\n",
    "\n",
    "with sns.plotting_context('paper', font_scale = 1.8):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(9,5))\n",
    "    fig.patch.set_alpha(1)\n",
    "    sns.despine() #bottom=True, left=True \n",
    "\n",
    "    sns.histplot(data=probs, kde=True)\n",
    "\n",
    "    ax.set(xlabel='Prediction Probability for Class Idle', ylabel='Frequency', title='Histogram of probabilities')\n",
    "\n",
    "probs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(data, classes)\n",
    "\n",
    "# clf.predict_proba(pre_move_ems1_means)\n",
    "\n",
    "print('Accuracy score : \\n' + str(accuracy_score(pre_move_ems1_class, clf.predict(pre_move_ems1_means))))\n",
    "print('Accuracy score : \\n' + str(accuracy_score(idle_ems1_class, clf.predict(idle_ems1_means))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Dimensionality Reduction with Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "lda_scores_training = clf.transform(data)\n",
    "rf.fit(lda_scores_training, classes)\n",
    "\n",
    "lda_scores_experiment = clf.transform(idle_ems1_means)\n",
    "y_pred = rf.predict(lda_scores_experiment)\n",
    "\n",
    "print('Accuracy score : \\n' + str(accuracy_score(idle_ems1_class, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
