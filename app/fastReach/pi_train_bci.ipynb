{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "pID = 6\n",
    "pID = 'sub-' + \"%03d\" % (pID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.ensemble import AdaBoostClassifier as ABC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "import pickle, json, os\n",
    "import scipy.io\n",
    "from bci_funcs import windowed_mean, base_correct, select_mean, slope\n",
    "\n",
    "# path = 'P:\\\\Lukas_Gehrke\\\\fastReach\\\\data\\\\eeglab2python'\n",
    "path = '/Volumes/Lukas_Gehrke/fastReach/data/eeglab2python'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preconscious Augmentation\n",
    "\n",
    "This script trains the classifier for a brain-computer interface that controls electrical muscle stimulation in the preconscious augmentation experiment.\n",
    "The functions used to build the feature vectors are the same that are used for the online application and are found in 'bci_funcs'\n",
    "\n",
    "A two class linear discriminant model is fitted to idle and pre-movement EEG training data. The model and a channel selection is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "pre_move = scipy.io.loadmat(path+os.sep+pID+os.sep+'pre_move_Baseline.mat')\n",
    "idle = scipy.io.loadmat(path+os.sep+pID+os.sep+'idle_Baseline.mat')\n",
    "all_idle = idle['idle']\n",
    "all_pre_move = pre_move['pre_move']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Best Channels by Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slope_idle = np.zeros((idle.shape[2], idle.shape[0]))\n",
    "# slope_pre_move = np.zeros((pre_move.shape[2], pre_move.shape[0]))\n",
    "\n",
    "# for trial_ix in range(0, pre_move.shape[2]):\n",
    "#     slope_pre_move[trial_ix, :] = slope(pre_move[:,:,trial_ix], 'linear').flatten()\n",
    "\n",
    "# for trial_ix in range(0, idle.shape[2]):\n",
    "#     slope_idle[trial_ix, :] = slope(idle[:,:,trial_ix], 'linear').flatten()\n",
    "\n",
    "# crit1 = pd.DataFrame(slope_pre_move.mean(axis=0)).sort_values(by=0, ascending=False)\n",
    "# crit1['chans'] = crit1.index\n",
    "# crit1['crit1_ranks'] = crit1.reset_index().index\n",
    "# crit1.sort_values(by='chans', inplace=True)\n",
    "\n",
    "# crit2 = pd.DataFrame(slope_idle.mean(axis=0)).sort_values(by=0, ascending=True)\n",
    "# crit2['chans'] = crit2.index\n",
    "# crit2['crit2_ranks'] = crit2.reset_index().index\n",
    "# crit2.sort_values(by='chans', inplace=True)\n",
    "\n",
    "# crits = pd.concat([crit1.chans, crit1.crit1_ranks, crit2.crit2_ranks], axis=1)\n",
    "# crits['mean_ranks'] = crits[['crit1_ranks', 'crit2_ranks']].mean(axis=1)\n",
    "# crits.sort_values(by='mean_ranks', inplace=True)\n",
    "# chans = crits.chans.values\n",
    "\n",
    "# chans = chans[:nr_chans]\n",
    "# chan_names.Var1[chans]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = slope\n",
    "\n",
    "# data_to_plot = pd.DataFrame(data)\n",
    "# data_to_plot['class'] = classes\n",
    "# data_to_plot = data_to_plot.melt(id_vars = 'class', value_name = 'amplitude')\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.set_theme(style=\"ticks\")\n",
    "# sns.displot(x=\"amplitude\", hue=\"class\", data=data_to_plot, kde=True, fill=True, stat=\"density\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lazypredict.Supervised import LazyClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for i in range(1, 10):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(np.asarray(data), classes, test_size=.1)#,random_state =123)\n",
    "\n",
    "#     clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "#     models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "#     print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Features & Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 channels\n",
      "LDA accuracy: 0.6404761904761905 +/- 0.049026810195176206\n",
      "ABC accuracy: 0.6843915343915344 +/- 0.080527640448701\n",
      "QDA accuracy: 0.7492063492063492 +/- 0.09191970161216605\n",
      "RFC accuracy: 0.7275132275132276 +/- 0.07849166671024589\n",
      "15 channels\n",
      "LDA accuracy: 0.6119047619047618 +/- 0.038095238095238106\n",
      "ABC accuracy: 0.641005291005291 +/- 0.08820520013254253\n",
      "QDA accuracy: 0.6984126984126984 +/- 0.0717365494506455\n",
      "RFC accuracy: 0.6915343915343916 +/- 0.08127507699184096\n",
      "20 channels\n",
      "LDA accuracy: 0.6042328042328042 +/- 0.05084185323058649\n",
      "ABC accuracy: 0.6978835978835979 +/- 0.0971969336869399\n",
      "QDA accuracy: 0.647883597883598 +/- 0.04461732564060183\n",
      "RFC accuracy: 0.7407407407407407 +/- 0.07716981551150617\n"
     ]
    }
   ],
   "source": [
    "# ### COPY IN WHERE BEST CLASSIFICATION PERFORMANCE WAS ACHIEVED ###\n",
    "# filename = path+os.sep+pID+os.sep+'model_'+pID+'_eeg.sav'\n",
    "# pickle.dump(clf, open(filename, 'wb'))\n",
    "\n",
    "# threshold = cv_results.mean()\n",
    "# bci_params = dict(((k, eval(k)) for k in ('chans', 'windows', 'baseline', 'target_class', 'threshold', 'data_srate', 'classifier_update_rate')))\n",
    "# with open(path+os.sep+pID+os.sep+'bci_params.json', 'w') as f:\n",
    "#     json.dump(bci_params, f)\n",
    "# ### END ###\n",
    "\n",
    "nr_chans_arr = np.arange(10,21,5) # select one and then save the model\n",
    "\n",
    "data_srate = 250\n",
    "windows = 10\n",
    "baseline = data_srate/windows\n",
    "target_class = 1.0\n",
    "classifier_update_rate = 5 # samples\n",
    "\n",
    "chan_names = pd.read_csv(path+os.sep+pID+os.sep+'sel_chans_names.csv')\n",
    "chans = pd.read_csv(path+os.sep+pID+os.sep+'sel_chans.csv', header=None)\n",
    "\n",
    "feat = 'slope' # slope or slope_2d\n",
    "\n",
    "for nr_chans in nr_chans_arr:\n",
    "    print(str(nr_chans) + ' channels')\n",
    "\n",
    "    chans = np.squeeze(np.array(chans[0:nr_chans]) - 1).tolist()\n",
    "    # chan_names.Var1[chans]\n",
    "\n",
    "    idle = all_idle[chans, :, :]\n",
    "    pre_move = all_pre_move[chans, :, :]\n",
    "\n",
    "    if feat == 'slope':\n",
    "        idle_feat = np.zeros((idle.shape[2], idle.shape[0]))\n",
    "        pre_move_feat = np.zeros((pre_move.shape[2], pre_move.shape[0]))\n",
    "\n",
    "    elif feat == 'slope2d':\n",
    "        idle_feat = np.zeros((idle.shape[2], idle.shape[0]*2))\n",
    "        pre_move_feat = np.zeros((pre_move.shape[2], pre_move.shape[0]*2))\n",
    "\n",
    "    elif feat == 'windowed_means':\n",
    "        idle_feat = np.zeros((idle.shape[2], idle.shape[0] * (windows)))\n",
    "        pre_move_feat = np.zeros((pre_move.shape[2], pre_move.shape[0] * (windows)))\n",
    "\n",
    "    for trial_ix in range(0, pre_move.shape[2]):\n",
    "        if feat == 'slope':\n",
    "            pre_move_feat[trial_ix, :] = slope(pre_move[:,:,trial_ix], 'linear').flatten()\n",
    "        \n",
    "        elif feat == 'slope2d':\n",
    "            pre_move_feat[trial_ix, :idle.shape[0]] = slope(pre_move[:,:150,trial_ix], 'linear').flatten()\n",
    "            pre_move_feat[trial_ix, idle.shape[0]:] = slope(pre_move[:,150:,trial_ix], 'linear').flatten()\n",
    "\n",
    "        elif feat == 'windowed_means':\n",
    "            tmp = base_correct(pre_move[:,:,trial_ix], baseline-1)\n",
    "            pre_move_feat[trial_ix, :] = windowed_mean(tmp, windows).flatten()\n",
    "\n",
    "    for trial_ix in range(0, idle.shape[2]):\n",
    "        if feat == 'slope':\n",
    "            idle_feat[trial_ix, :] = slope(idle[:,:,trial_ix], 'linear').flatten()    \n",
    "        \n",
    "        elif feat == 'slope2d':\n",
    "            idle_feat[trial_ix, :idle.shape[0]] = slope(idle[:,:150,trial_ix], 'linear').flatten()\n",
    "            idle_feat[trial_ix, idle.shape[0]:] = slope(idle[:,150:,trial_ix], 'linear').flatten()\n",
    "\n",
    "        elif feat == 'windowed_means':\n",
    "            tmp = base_correct(idle[:,:,trial_ix], baseline-1)\n",
    "            idle_feat[trial_ix, :] = windowed_mean(tmp, windows).flatten()\n",
    "\n",
    "    data = np.concatenate((pre_move_feat, idle_feat), axis = 0)\n",
    "    pre_move_class = np.ones((pre_move_feat.shape[0], 1))\n",
    "    idle_class = np.zeros((idle_feat.shape[0], 1))\n",
    "    classes = np.concatenate((pre_move_class, idle_class)).ravel()\n",
    "\n",
    "    clf = LDA(solver='eigen', shrinkage='auto')\n",
    "    clf.fit(data, classes)\n",
    "    kfolds = KFold(n_splits=5, random_state=1, shuffle=True) \n",
    "    cv_results = cross_val_score(clf, data, classes, cv=kfolds)\n",
    "    print(\"LDA accuracy: \" + str(cv_results.mean()) + \" +/- \" + str(cv_results.std()))\n",
    "\n",
    "    clf = ABC()\n",
    "    clf.fit(data, classes)\n",
    "    kfolds = KFold(n_splits=5, random_state=1, shuffle=True) \n",
    "    cv_results = cross_val_score(clf, data, classes, cv=kfolds)\n",
    "    print(\"ABC accuracy: \" + str(cv_results.mean()) + \" +/- \" + str(cv_results.std()))\n",
    "\n",
    "    clf = QDA()\n",
    "    clf.fit(data, classes)\n",
    "    kfolds = KFold(n_splits=5, random_state=1, shuffle=True) \n",
    "    cv_results = cross_val_score(clf, data, classes, cv=kfolds)\n",
    "    print(\"QDA accuracy: \" + str(cv_results.mean()) + \" +/- \" + str(cv_results.std()))\n",
    "\n",
    "    clf = RFC()\n",
    "    clf.fit(data, classes)\n",
    "    kfolds = KFold(n_splits=5, random_state=1, shuffle=True) \n",
    "    cv_results = cross_val_score(clf, data, classes, cv=kfolds)\n",
    "    print(\"RFC accuracy: \" + str(cv_results.mean()) + \" +/- \" + str(cv_results.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
